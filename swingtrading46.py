import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import time
import pytz
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# NLTK and VADER Sentiment Setup
import nltk
try:
    nltk.data.find('sentiment/vader_lexicon.zip')
except LookupError:
    nltk.download('vader_lexicon', quiet=True)

from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Page Configuration
st.set_page_config(
    page_title="Professional Trading System",
    page_icon="ðŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .signal-box {
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
        font-weight: bold;
        font-size: 1.2rem;
    }
    .buy-signal {
        background-color: #d4edda;
        border: 2px solid #28a745;
        color: #155724;
    }
    .sell-signal {
        background-color: #f8d7da;
        border: 2px solid #dc3545;
        color: #721c24;
    }
    .hold-signal {
        background-color: #fff3cd;
        border: 2px solid #ffc107;
        color: #856404;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 15px;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
    }
    .stButton>button {
        width: 100%;
        background-color: #1f77b4;
        color: white;
        font-weight: bold;
        border-radius: 5px;
        padding: 10px;
    }
</style>
""", unsafe_allow_html=True)

# Data Classes
@dataclass
class TradingSignal:
    action: str  # BUY, SELL, HOLD
    confidence: float
    entry_price: float
    target_price: float
    stop_loss: float
    timeframe: str
    strategy: str
    reasoning: str
    risk_reward: float
    sentiment_score: float = 0
    sentiment_summary: str = ""
    strong_support: float = 0
    strong_resistance: float = 0
    support_strength: str = ""
    resistance_strength: str = ""
    zscore: float = 0
    zscore_interpretation: str = ""
    timeframe_signals: Dict = None
    detailed_summary: str = ""
    signal_confluence: str = ""

@dataclass
class BacktestResult:
    total_trades: int
    winning_trades: int
    losing_trades: int
    win_rate: float
    avg_profit: float
    avg_loss: float
    profit_factor: float
    max_drawdown: float
    total_return: float
    annual_return: float = 0
    sharpe_ratio: float = 0


@dataclass
class VolatilityAnalysis:
    historical_volatility: float
    atr_volatility: float
    volatility_percentile: float
    volatility_regime: str
    impact_on_trading: str

# Instrument Mappings
INSTRUMENTS = {
    "NIFTY 50": "^NSEI",
    "BANK NIFTY": "^NSEBANK",
    "SENSEX": "^BSESN",
    "Bitcoin": "BTC-USD",
    "Ethereum": "ETH-USD",
    "Gold": "GC=F",
    "Silver": "SI=F",
    "USD/INR": "INR=X",
    "EUR/USD": "EURUSD=X",
    "Custom Ticker": "CUSTOM"
}

TIMEFRAMES = ["1m", "3m", "5m", "10m", "15m", "30m", "1h", "2h", "4h", "1d"]
PERIODS = ["1d", "5d", "7d", "1mo", "3mo", "6mo", "1y", "2y", "3y", "5y", "10y", "15y", "20y"]

# Session State Initialization
if 'data_cache' not in st.session_state:
    st.session_state.data_cache = {}
if 'last_fetch_time' not in st.session_state:
    st.session_state.last_fetch_time = {}
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None

class TechnicalAnalyzer:
    """Advanced Technical Analysis Engine"""
    
    @staticmethod
    def calculate_indicators(df: pd.DataFrame) -> pd.DataFrame:
        """Calculate comprehensive technical indicators"""
        df = df.copy()
        
        # Moving Averages
        df['SMA_20'] = df['Close'].rolling(window=20).mean()
        df['SMA_50'] = df['Close'].rolling(window=50).mean()
        df['SMA_200'] = df['Close'].rolling(window=200).mean()
        df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()
        df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()
        
        # MACD
        df['MACD'] = df['EMA_12'] - df['EMA_26']
        df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
        df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']
        
        # RSI
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # Bollinger Bands
        df['BB_Middle'] = df['Close'].rolling(window=20).mean()
        bb_std = df['Close'].rolling(window=20).std()
        df['BB_Upper'] = df['BB_Middle'] + (bb_std * 2)
        df['BB_Lower'] = df['BB_Middle'] - (bb_std * 2)
        
        # ATR (Average True Range)
        high_low = df['High'] - df['Low']
        high_close = np.abs(df['High'] - df['Close'].shift())
        low_close = np.abs(df['Low'] - df['Close'].shift())
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = np.max(ranges, axis=1)
        df['ATR'] = true_range.rolling(14).mean()
        
        # Stochastic Oscillator
        low_14 = df['Low'].rolling(window=14).min()
        high_14 = df['High'].rolling(window=14).max()
        df['Stoch_K'] = 100 * ((df['Close'] - low_14) / (high_14 - low_14))
        df['Stoch_D'] = df['Stoch_K'].rolling(window=3).mean()
        
        # ADX (Average Directional Index)
        df['ADX'] = TechnicalAnalyzer.calculate_adx(df)
        
        # Volume indicators
        df['Volume_SMA'] = df['Volume'].rolling(window=20).mean()
        df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA']
        
        # Support and Resistance
        df['Support'] = df['Low'].rolling(window=20).min()
        df['Resistance'] = df['High'].rolling(window=20).max()
        
        return df
    
    @staticmethod
    def calculate_adx(df: pd.DataFrame, period: int = 14) -> pd.Series:
        """Calculate Average Directional Index"""
        high = df['High']
        low = df['Low']
        close = df['Close']
        
        plus_dm = high.diff()
        minus_dm = -low.diff()
        plus_dm[plus_dm < 0] = 0
        minus_dm[minus_dm < 0] = 0
        
        tr = pd.DataFrame({
            'hl': high - low,
            'hc': abs(high - close.shift()),
            'lc': abs(low - close.shift())
        }).max(axis=1)
        
        atr = tr.rolling(window=period).mean()
        plus_di = 100 * (plus_dm.rolling(window=period).mean() / atr)
        minus_di = 100 * (minus_dm.rolling(window=period).mean() / atr)
        
        dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di)
        adx = dx.rolling(window=period).mean()
        
        return adx


class DataFetcher:
    """Handles data fetching with rate limiting"""
    
    @staticmethod
    def fetch_data(ticker: str, period: str, interval: str) -> pd.DataFrame:
        """Fetch data with rate limiting and error handling"""
        
        cache_key = f"{ticker}_{period}_{interval}"
        current_time = time.time()
        
        # Check cache (5 minutes validity)
        if cache_key in st.session_state.data_cache:
            cached_data, cache_time = st.session_state.data_cache[cache_key]
            if current_time - cache_time < 300:  # 5 minutes
                return cached_data
        
        # Rate limiting
        if cache_key in st.session_state.last_fetch_time:
            time_since_last = current_time - st.session_state.last_fetch_time[cache_key]
            if time_since_last < 1.5:
                time.sleep(1.5 - time_since_last)
        
        try:
            # Fetch data
            stock = yf.Ticker(ticker)
            df = stock.history(period=period, interval=interval)
            
            if df.empty:
                st.error(f"No data available for {ticker}")
                return pd.DataFrame()
            
            # Convert to IST
            if df.index.tz is not None:
                df.index = df.index.tz_convert('Asia/Kolkata')
            else:
                df.index = df.index.tz_localize('UTC').tz_convert('Asia/Kolkata')
            
            # Fetch news
            try:
                news = stock.news[:5] if hasattr(stock, 'news') else []
                df.attrs['news'] = news
            except:
                df.attrs['news'] = []
            
            # Cache data
            st.session_state.data_cache[cache_key] = (df, current_time)
            st.session_state.last_fetch_time[cache_key] = current_time
            
            return df
            
        except Exception as e:
            st.error(f"Error fetching data: {str(e)}")
            return pd.DataFrame()


class SentimentAnalyzer:
    """News Sentiment Analysis using VADER"""
    
    def __init__(self, ticker: str):
        self.ticker = ticker
        self.vader = SentimentIntensityAnalyzer()
    
    def analyze(self) -> Dict:
        """Analyze news sentiment"""
        try:
            news = yf.Ticker(self.ticker).news
            
            if not news:
                return {"score": 0, "summary": "No Recent News", "details": []}
            
            score = 0
            news_details = []
            valid_count = 0
            
            for n in news[:5]:
                try:
                    # Try different ways to access title
                    title = None
                    if 'title' in n:
                        title = n['title']
                    elif 'content' in n and 'title' in n['content']:
                        title = n['content']['title']
                    
                    if not title:
                        continue
                    
                    sentiment_score = self.vader.polarity_scores(title)['compound']
                    score += sentiment_score
                    valid_count += 1
                    
                    news_details.append({
                        'title': title,
                        'score': sentiment_score,
                        'link': n.get('link', '#')
                    })
                    
                except Exception as e:
                    continue
            
            if valid_count == 0:
                return {"score": 0, "summary": "No Valid News", "details": []}
            
            avg_score = score / valid_count
            
            # Determine sentiment
            sentiment = "NEUTRAL"
            if avg_score > 0.15:
                sentiment = "POSITIVE (News Catalyst)"
            elif avg_score < -0.15:
                sentiment = "NEGATIVE (Bad Press)"
            
            return {
                "score": avg_score,
                "summary": sentiment,
                "details": news_details
            }
            
        except Exception as e:
            return {"score": 0, "summary": f"Error: {str(e)}", "details": []}

    """News Sentiment Analysis using VADER"""
    
    def __init__(self, ticker: str):
        self.ticker = ticker
        self.vader = SentimentIntensityAnalyzer()
    
    def analyze(self) -> Dict:
        """Analyze news sentiment"""
        try:
            news = yf.Ticker(self.ticker).news
            
            if not news:
                return {"score": 0, "summary": "No Recent News", "details": []}
            
            scores = []
            news_details = []
            
            for n in news[:5]:
                try:
                    title = n.get('title', '')
                    if not title:
                        continue
                    
                    sentiment_score = self.vader.polarity_scores(title)['compound']
                    scores.append(sentiment_score)
                    
                    news_details.append({
                        'title': title,
                        'score': sentiment_score,
                        'link': n.get('link', '#')
                    })
                    
                except Exception as e:
                    continue
            
            if not scores:
                return {"score": 0, "summary": "No Valid News", "details": []}
            
            avg_score = sum(scores) / len(scores)
            
            # Determine sentiment
            if avg_score > 0.25:
                sentiment = "VERY POSITIVE (Strong Bullish Catalyst)"
            elif avg_score > 0.15:
                sentiment = "POSITIVE (Mild Bullish News)"
            elif avg_score < -0.25:
                sentiment = "VERY NEGATIVE (Strong Bearish Catalyst)"
            elif avg_score < -0.15:
                sentiment = "NEGATIVE (Mild Bearish News)"
            else:
                sentiment = "NEUTRAL (No Significant News Impact)"
            
            return {
                "score": avg_score,
                "summary": sentiment,
                "details": news_details
            }
            
        except Exception as e:
            return {"score": 0, "summary": f"Error analyzing sentiment: {str(e)}", "details": []}


class VolatilityAnalyzer:
    """Advanced Volatility Analysis"""
    
    @staticmethod
    def analyze_volatility(df: pd.DataFrame) -> VolatilityAnalysis:
        """Comprehensive volatility analysis"""
        
        if len(df) < 30:
            return VolatilityAnalysis(0, 0, 0, "UNKNOWN", "Insufficient data")
        
        # Historical Volatility (standard deviation of returns)
        returns = df['Close'].pct_change().dropna()
        hist_vol = returns.std() * np.sqrt(252) * 100  # Annualized
        
        # ATR-based volatility
        latest = df.iloc[-1]
        atr_vol = (latest['ATR'] / latest['Close']) * 100
        
        # Compare to historical percentile
        rolling_vol = returns.rolling(window=20).std() * np.sqrt(252) * 100
        current_vol_percentile = (rolling_vol < hist_vol).sum() / len(rolling_vol) * 100
        
        # Determine volatility regime
        if current_vol_percentile > 80:
            regime = "EXTREME HIGH"
            impact = "Very high volatility increases risk. Use wider stops, smaller position sizes. Breakout strategies work better."
        elif current_vol_percentile > 60:
            regime = "HIGH"
            impact = "Elevated volatility. Increase stop distances by 20%. Momentum strategies favored."
        elif current_vol_percentile > 40:
            regime = "NORMAL"
            impact = "Normal volatility regime. Standard position sizing and stop distances appropriate."
        elif current_vol_percentile > 20:
            regime = "LOW"
            impact = "Low volatility. Tighter stops acceptable. Mean reversion strategies work better."
        else:
            regime = "EXTREME LOW"
            impact = "Very low volatility often precedes breakouts. Prepare for volatility expansion."
        
        return VolatilityAnalysis(
            historical_volatility=hist_vol,
            atr_volatility=atr_vol,
            volatility_percentile=current_vol_percentile,
            volatility_regime=regime,
            impact_on_trading=impact
        )


class SupportResistanceAnalyzer:
    """Advanced Support and Resistance Analysis"""
    
    @staticmethod
    def find_all_strong_levels(df: pd.DataFrame, max_levels: int = 5) -> Dict:
        """Identify multiple strong support and resistance levels"""
        
        if len(df) < 50:
            return {
                'supports': [],
                'resistances': [],
                'primary_support': df['Low'].min(),
                'primary_resistance': df['High'].max()
            }
        
        close_prices = df['Close'].values
        high_prices = df['High'].values
        low_prices = df['Low'].values
        
        window = 10
        resistance_levels = []
        support_levels = []
        
        # Identify local maxima and minima
        for i in range(window, len(df) - window):
            if high_prices[i] == max(high_prices[i-window:i+window+1]):
                resistance_levels.append({
                    'price': high_prices[i],
                    'index': i,
                    'date': df.index[i]
                })
            
            if low_prices[i] == min(low_prices[i-window:i+window+1]):
                support_levels.append({
                    'price': low_prices[i],
                    'index': i,
                    'date': df.index[i]
                })
        
        current_price = close_prices[-1]
        
        # Cluster and rank supports
        support_clusters = SupportResistanceAnalyzer._cluster_and_rank_levels(
            support_levels, current_price, 'support', df
        )
        
        # Cluster and rank resistances
        resistance_clusters = SupportResistanceAnalyzer._cluster_and_rank_levels(
            resistance_levels, current_price, 'resistance', df
        )
        
        return {
            'supports': support_clusters[:max_levels],
            'resistances': resistance_clusters[:max_levels],
            'primary_support': support_clusters[0]['price'] if support_clusters else df['Low'].min(),
            'primary_resistance': resistance_clusters[0]['price'] if resistance_clusters else df['High'].max()
        }
    
    @staticmethod
    def _cluster_and_rank_levels(levels: List, current_price: float, 
                                 level_type: str, df: pd.DataFrame) -> List:
        """Cluster nearby levels and rank by strength"""
        
        if not levels:
            return []
        
        clustered = {}
        
        for level in levels:
            price = level['price']
            
            # Skip if wrong side of current price
            if level_type == 'support' and price > current_price:
                continue
            if level_type == 'resistance' and price < current_price:
                continue
            
            # Find or create cluster
            found_cluster = False
            for cluster_price in list(clustered.keys()):
                if abs(price - cluster_price) / cluster_price < 0.02:
                    clustered[cluster_price]['touches'] += 1
                    clustered[cluster_price]['dates'].append(level['date'])
                    found_cluster = True
                    break
            
            if not found_cluster:
                clustered[price] = {
                    'price': price,
                    'touches': 1,
                    'dates': [level['date']],
                    'distance': abs((price - current_price) / current_price * 100)
                }
        
        # Rank by touches and proximity
        ranked = sorted(clustered.values(), 
                       key=lambda x: (x['touches'] * 10 - x['distance']), 
                       reverse=True)
        
        # Add strength description
        for level in ranked:
            touches = level['touches']
            if touches >= 5:
                level['strength'] = f"VERY STRONG (tested {touches} times)"
            elif touches >= 3:
                level['strength'] = f"STRONG (tested {touches} times)"
            else:
                level['strength'] = f"MODERATE (tested {touches} times)"
        
        return ranked
    """Advanced Support and Resistance Analysis"""
    
    @staticmethod
    def find_strong_levels(df: pd.DataFrame) -> Dict:
        """Identify strong support and resistance levels"""
        
        if len(df) < 50:
            return {
                'support': df['Low'].min(),
                'resistance': df['High'].max(),
                'support_strength': 'Insufficient data',
                'resistance_strength': 'Insufficient data',
                'support_touches': 0,
                'resistance_touches': 0
            }
        
        # Use multiple timeframe approach
        close_prices = df['Close'].values
        high_prices = df['High'].values
        low_prices = df['Low'].values
        
        # Find pivot points
        window = 10
        resistance_levels = []
        support_levels = []
        
        # Identify local maxima and minima
        for i in range(window, len(df) - window):
            # Resistance (local maxima)
            if high_prices[i] == max(high_prices[i-window:i+window+1]):
                resistance_levels.append(high_prices[i])
            
            # Support (local minima)
            if low_prices[i] == min(low_prices[i-window:i+window+1]):
                support_levels.append(low_prices[i])
        
        current_price = close_prices[-1]
        
        # Find strongest support (closest below current price with most touches)
        supports_below = [s for s in support_levels if s < current_price]
        if supports_below:
            # Cluster nearby levels
            support_clusters = SupportResistanceAnalyzer._cluster_levels(supports_below)
            strong_support = max(support_clusters.keys())
            support_touches = support_clusters[strong_support]
        else:
            strong_support = df['Low'].min()
            support_touches = 1
        
        # Find strongest resistance (closest above current price with most touches)
        resistances_above = [r for r in resistance_levels if r > current_price]
        if resistances_above:
            resistance_clusters = SupportResistanceAnalyzer._cluster_levels(resistances_above)
            strong_resistance = min(resistance_clusters.keys())
            resistance_touches = resistance_clusters[strong_resistance]
        else:
            strong_resistance = df['High'].max()
            resistance_touches = 1
        
        # Calculate strength based on touches and volume
        volume_at_support = SupportResistanceAnalyzer._volume_at_level(
            df, strong_support, tolerance=0.02
        )
        volume_at_resistance = SupportResistanceAnalyzer._volume_at_level(
            df, strong_resistance, tolerance=0.02
        )
        
        # Strength interpretation
        support_strength = SupportResistanceAnalyzer._interpret_strength(
            support_touches, volume_at_support, "Support"
        )
        resistance_strength = SupportResistanceAnalyzer._interpret_strength(
            resistance_touches, volume_at_resistance, "Resistance"
        )
        
        return {
            'support': strong_support,
            'resistance': strong_resistance,
            'support_strength': support_strength,
            'resistance_strength': resistance_strength,
            'support_touches': support_touches,
            'resistance_touches': resistance_touches,
            'support_distance': ((current_price - strong_support) / current_price) * 100,
            'resistance_distance': ((strong_resistance - current_price) / current_price) * 100
        }
    
    @staticmethod
    def _cluster_levels(levels: List[float], tolerance: float = 0.02) -> Dict:
        """Cluster nearby price levels and count touches"""
        clusters = {}
        
        for level in levels:
            found_cluster = False
            for cluster_level in list(clusters.keys()):
                if abs(level - cluster_level) / cluster_level < tolerance:
                    clusters[cluster_level] += 1
                    found_cluster = True
                    break
            
            if not found_cluster:
                clusters[level] = 1
        
        return clusters
    
    @staticmethod
    def _volume_at_level(df: pd.DataFrame, level: float, tolerance: float = 0.02) -> float:
        """Calculate average volume when price was near this level"""
        mask = (df['Close'] >= level * (1 - tolerance)) & (df['Close'] <= level * (1 + tolerance))
        if mask.sum() > 0:
            return df.loc[mask, 'Volume'].mean()
        return df['Volume'].mean()
    
    @staticmethod
    def _interpret_strength(touches: int, volume: float, level_type: str) -> str:
        """Interpret the strength of support/resistance"""
        
        strength_score = touches * 2
        
        if touches >= 5:
            strength = "VERY STRONG"
            reason = f"Tested {touches} times and held. This is a critical {level_type.lower()} zone."
        elif touches >= 3:
            strength = "STRONG"
            reason = f"Tested {touches} times. Significant {level_type.lower()} level."
        elif touches >= 2:
            strength = "MODERATE"
            reason = f"Tested {touches} times. Established {level_type.lower()}."
        else:
            strength = "WEAK"
            reason = f"Only tested {touches} time. Unconfirmed {level_type.lower()}."
        
        importance = f"{strength} - {reason} High volume activity at this level increases its reliability."
        
        return importance


class ZScoreAnalyzer:
    """Z-Score Analysis for Mean Reversion and Extreme Conditions"""
    
    @staticmethod
    def calculate_zscore(df: pd.DataFrame, window: int = 20) -> Dict:
        """Calculate Z-Score and interpret its impact"""
        
        if len(df) < window:
            return {
                'current_zscore': 0,
                'interpretation': 'Insufficient data',
                'historical_impact': 'N/A',
                'future_outlook': 'N/A'
            }
        
        # Calculate rolling Z-Score
        close_prices = df['Close']
        rolling_mean = close_prices.rolling(window=window).mean()
        rolling_std = close_prices.rolling(window=window).std()
        
        zscore = (close_prices - rolling_mean) / rolling_std
        df['ZScore'] = zscore
        
        current_zscore = zscore.iloc[-1]
        
        # Historical analysis
        historical_analysis = ZScoreAnalyzer._analyze_historical_zscore(df, window)
        
        # Current interpretation
        if current_zscore > 2:
            interpretation = "EXTREMELY OVERBOUGHT"
            signal = "Strong mean reversion expected - consider selling"
        elif current_zscore > 1.5:
            interpretation = "OVERBOUGHT"
            signal = "Price extended above mean - potential pullback"
        elif current_zscore > 1:
            interpretation = "MODERATELY OVERBOUGHT"
            signal = "Price above average - watch for reversal"
        elif current_zscore < -2:
            interpretation = "EXTREMELY OVERSOLD"
            signal = "Strong mean reversion expected - consider buying"
        elif current_zscore < -1.5:
            interpretation = "OVERSOLD"
            signal = "Price extended below mean - potential bounce"
        elif current_zscore < -1:
            interpretation = "MODERATELY OVERSOLD"
            signal = "Price below average - watch for recovery"
        else:
            interpretation = "NEUTRAL"
            signal = "Price near historical average - no extreme condition"
        
        # Future outlook
        future_outlook = ZScoreAnalyzer._forecast_based_on_zscore(
            current_zscore, historical_analysis
        )
        
        return {
            'current_zscore': current_zscore,
            'interpretation': f"{interpretation} (Z={current_zscore:.2f})",
            'signal': signal,
            'historical_impact': historical_analysis,
            'future_outlook': future_outlook
        }
    
    @staticmethod
    def _analyze_historical_zscore(df: pd.DataFrame, window: int) -> str:
        """Analyze how Z-Score behaved historically"""
        
        zscore = df['ZScore'].dropna()
        
        if len(zscore) < 50:
            return "Limited historical data for Z-Score analysis"
        
        # Count extreme events
        extreme_high = (zscore > 2).sum()
        extreme_low = (zscore < -2).sum()
        
        # Check mean reversion success rate
        reversion_success = 0
        total_extremes = 0
        
        for i in range(len(zscore) - 10):
            if zscore.iloc[i] > 2:  # Overbought
                # Check if price reverted in next 10 periods
                future_prices = df['Close'].iloc[i+1:i+11]
                if future_prices.min() < df['Close'].iloc[i]:
                    reversion_success += 1
                total_extremes += 1
            
            elif zscore.iloc[i] < -2:  # Oversold
                future_prices = df['Close'].iloc[i+1:i+11]
                if future_prices.max() > df['Close'].iloc[i]:
                    reversion_success += 1
                total_extremes += 1
        
        success_rate = (reversion_success / total_extremes * 100) if total_extremes > 0 else 0
        
        analysis = f"Historical Z-Score analysis: {extreme_high} overbought events, "
        analysis += f"{extreme_low} oversold events. Mean reversion success rate: {success_rate:.1f}%. "
        
        if success_rate > 70:
            analysis += "Strong historical tendency to revert to mean."
        elif success_rate > 50:
            analysis += "Moderate mean reversion tendency."
        else:
            analysis += "Weak mean reversion - trending market."
        
        return analysis
    
    @staticmethod
    def _forecast_based_on_zscore(current_zscore: float, historical: str) -> str:
        """Forecast future price movement based on Z-Score"""
        
        if current_zscore > 2:
            forecast = "HIGH PROBABILITY of price decline in coming sessions. "
            forecast += "Z-Score above 2 indicates extreme deviation from mean. "
            forecast += "Historical data suggests mean reversion is likely. "
            forecast += "Consider taking profits or waiting for pullback before entering longs."
        
        elif current_zscore > 1:
            forecast = "MODERATE PROBABILITY of consolidation or mild pullback. "
            forecast += "Price is stretched but not at extreme levels. "
            forecast += "Could continue higher with momentum, but risk/reward favors caution."
        
        elif current_zscore < -2:
            forecast = "HIGH PROBABILITY of price recovery in coming sessions. "
            forecast += "Z-Score below -2 indicates extreme undervaluation relative to recent mean. "
            forecast += "Historical patterns suggest strong bounce potential. "
            forecast += "Risk/reward favors buying at these oversold levels."
        
        elif current_zscore < -1:
            forecast = "MODERATE PROBABILITY of upward move. "
            forecast += "Price below average presents opportunity. "
            forecast += "Could decline further, but statistical edge favors buyers."
        
        else:
            forecast = "NEUTRAL OUTLOOK - Price near equilibrium. "
            forecast += "No statistical edge from Z-Score. "
            forecast += "Rely on trend, momentum, and other technical indicators."
        
        return forecast


class FibonacciAnalyzer:
    """Fibonacci Retracement and Extension Analysis"""
    
    @staticmethod
    def calculate_fibonacci_levels(df: pd.DataFrame, lookback: int = 50) -> Dict:
        """Calculate Fibonacci retracement and extension levels"""
        
        if len(df) < lookback:
            lookback = len(df)
        
        recent_data = df.iloc[-lookback:]
        high = recent_data['High'].max()
        low = recent_data['Low'].min()
        diff = high - low
        
        current_price = df['Close'].iloc[-1]
        
        # Determine trend direction
        sma_20 = df['SMA_20'].iloc[-1] if 'SMA_20' in df.columns else current_price
        trend = "UPTREND" if current_price > sma_20 else "DOWNTREND"
        
        # Retracement levels (for pullbacks in trend)
        if trend == "UPTREND":
            fib_levels = {
                '0%': high,
                '23.6%': high - (diff * 0.236),
                '38.2%': high - (diff * 0.382),
                '50%': high - (diff * 0.50),
                '61.8%': high - (diff * 0.618),
                '78.6%': high - (diff * 0.786),
                '100%': low
            }
        else:  # DOWNTREND
            fib_levels = {
                '0%': low,
                '23.6%': low + (diff * 0.236),
                '38.2%': low + (diff * 0.382),
                '50%': low + (diff * 0.50),
                '61.8%': low + (diff * 0.618),
                '78.6%': low + (diff * 0.786),
                '100%': high
            }
        
        # Extension levels (for targets)
        if trend == "UPTREND":
            extensions = {
                '127.2%': high + (diff * 0.272),
                '161.8%': high + (diff * 0.618),
                '200%': high + diff,
                '261.8%': high + (diff * 1.618)
            }
        else:
            extensions = {
                '127.2%': low - (diff * 0.272),
                '161.8%': low - (diff * 0.618),
                '200%': low - diff,
                '261.8%': low - (diff * 1.618)
            }
        
        # Find nearest support/resistance
        nearest_support = None
        nearest_resistance = None
        min_dist_support = float('inf')
        min_dist_resistance = float('inf')
        
        for level_name, level_value in fib_levels.items():
            dist = abs(current_price - level_value)
            if level_value < current_price and dist < min_dist_support:
                nearest_support = (level_name, level_value)
                min_dist_support = dist
            elif level_value > current_price and dist < min_dist_resistance:
                nearest_resistance = (level_name, level_value)
                min_dist_resistance = dist
        
        return {
            'trend': trend,
            'levels': fib_levels,
            'extensions': extensions,
            'nearest_support': nearest_support,
            'nearest_resistance': nearest_resistance,
            'high': high,
            'low': low
        }


class RSIDivergenceAnalyzer:
    """RSI Divergence Detection"""
    
    @staticmethod
    def detect_divergence(df: pd.DataFrame, lookback: int = 20) -> Dict:
        """Detect bullish and bearish RSI divergences"""
        
        if len(df) < lookback or 'RSI' not in df.columns:
            return {'type': 'NONE', 'strength': 0, 'description': 'Insufficient data or RSI not available'}
        
        recent_df = df.iloc[-lookback:].copy()
        prices = recent_df['Close'].values
        rsi = recent_df['RSI'].values
        
        # Find peaks and troughs in price
        price_peaks = []
        price_troughs = []
        
        for i in range(2, len(prices) - 2):
            # Peak
            if prices[i] > prices[i-1] and prices[i] > prices[i-2] and \
               prices[i] > prices[i+1] and prices[i] > prices[i+2]:
                price_peaks.append((i, prices[i]))
            
            # Trough
            if prices[i] < prices[i-1] and prices[i] < prices[i-2] and \
               prices[i] < prices[i+1] and prices[i] < prices[i+2]:
                price_troughs.append((i, prices[i]))
        
        # Bearish Divergence (price making higher highs, RSI making lower highs)
        if len(price_peaks) >= 2:
            last_peak_idx, last_peak_price = price_peaks[-1]
            prev_peak_idx, prev_peak_price = price_peaks[-2]
            
            if last_peak_price > prev_peak_price and rsi[last_peak_idx] < rsi[prev_peak_idx]:
                strength = abs(rsi[prev_peak_idx] - rsi[last_peak_idx])
                return {
                    'type': 'BEARISH',
                    'strength': strength,
                    'description': f'Price made higher high ({prev_peak_price:.2f} -> {last_peak_price:.2f}) but RSI made lower high ({rsi[prev_peak_idx]:.1f} -> {rsi[last_peak_idx]:.1f}). Indicates weakening momentum - potential reversal down.'
                }
        
        # Bullish Divergence (price making lower lows, RSI making higher lows)
        if len(price_troughs) >= 2:
            last_trough_idx, last_trough_price = price_troughs[-1]
            prev_trough_idx, prev_trough_price = price_troughs[-2]
            
            if last_trough_price < prev_trough_price and rsi[last_trough_idx] > rsi[prev_trough_idx]:
                strength = abs(rsi[last_trough_idx] - rsi[prev_trough_idx])
                return {
                    'type': 'BULLISH',
                    'strength': strength,
                    'description': f'Price made lower low ({prev_trough_price:.2f} -> {last_trough_price:.2f}) but RSI made higher low ({rsi[prev_trough_idx]:.1f} -> {rsi[last_trough_idx]:.1f}). Indicates strengthening momentum - potential reversal up.'
                }
        
        return {
            'type': 'NONE',
            'strength': 0,
            'description': 'No significant divergence detected'
        }


class ElliottWaveAnalyzer:
    """Elliott Wave Pattern Detection"""
    
    @staticmethod
    def detect_elliott_wave(df: pd.DataFrame, lookback: int = 50) -> Dict:
        """Detect Elliott Wave patterns and current wave position"""
        
        if len(df) < lookback:
            lookback = len(df)
        
        recent_df = df.iloc[-lookback:].copy()
        prices = recent_df['Close'].values
        
        # Find significant pivots (simplified wave detection)
        pivots = ElliottWaveAnalyzer._find_pivots(prices)
        
        if len(pivots) < 5:
            return {
                'wave': 'UNKNOWN',
                'confidence': 0,
                'description': 'Insufficient pivot points for Elliott Wave analysis',
                'next_expected': 'N/A',
                'action_bias': 'HOLD'
            }
        
        # Analyze last 5 pivots for Elliott Wave pattern
        last_5_pivots = pivots[-5:]
        wave_pattern = ElliottWaveAnalyzer._identify_wave_pattern(last_5_pivots, prices)
        
        return wave_pattern
    
    @staticmethod
    def _find_pivots(prices: np.ndarray, order: int = 5) -> List:
        """Find pivot points (local maxima and minima)"""
        pivots = []
        
        for i in range(order, len(prices) - order):
            # Check for peak
            if all(prices[i] >= prices[i-j] for j in range(1, order+1)) and \
               all(prices[i] >= prices[i+j] for j in range(1, order+1)):
                pivots.append({'index': i, 'price': prices[i], 'type': 'HIGH'})
            
            # Check for trough
            elif all(prices[i] <= prices[i-j] for j in range(1, order+1)) and \
                 all(prices[i] <= prices[i+j] for j in range(1, order+1)):
                pivots.append({'index': i, 'price': prices[i], 'type': 'LOW'})
        
        return pivots
    
    @staticmethod
    def _identify_wave_pattern(pivots: List, prices: np.ndarray) -> Dict:
        """Identify Elliott Wave pattern from pivots"""
        
        current_price = prices[-1]
        last_pivot = pivots[-1]
        
        # Simplified pattern detection
        if len(pivots) >= 5:
            # Check for impulse pattern
            types = [p['type'] for p in pivots[-5:]]
            
            # Upward impulse: LOW, HIGH, LOW, HIGH, LOW (current above last high)
            if types == ['LOW', 'HIGH', 'LOW', 'HIGH', 'LOW']:
                wave_5_target = pivots[-2]['price']  # Wave 3 high
                
                if current_price > wave_5_target:
                    return {
                        'wave': 'WAVE 5 (Final Impulse Up)',
                        'confidence': 75,
                        'description': 'In final upward wave. Expect completion soon followed by correction. Wave 5 often equals Wave 1 in length.',
                        'next_expected': 'Corrective Wave A (Downward)',
                        'action_bias': 'SELL'
                    }
                else:
                    return {
                        'wave': 'WAVE 4 (Correction)',
                        'confidence': 70,
                        'description': 'In corrective Wave 4. Expect final Wave 5 push upward. Wave 4 typically retraces 38.2% of Wave 3.',
                        'next_expected': 'Wave 5 (Final Push Up)',
                        'action_bias': 'BUY_PENDING'
                    }
            
            # Downward impulse: HIGH, LOW, HIGH, LOW, HIGH
            elif types == ['HIGH', 'LOW', 'HIGH', 'LOW', 'HIGH']:
                wave_5_target = pivots[-2]['price']  # Wave 3 low
                
                if current_price < wave_5_target:
                    return {
                        'wave': 'WAVE 5 (Final Impulse Down)',
                        'confidence': 75,
                        'description': 'In final downward wave. Expect completion soon followed by correction upward.',
                        'next_expected': 'Corrective Wave A (Upward)',
                        'action_bias': 'BUY'
                    }
                else:
                    return {
                        'wave': 'WAVE 4 (Correction)',
                        'confidence': 70,
                        'description': 'In corrective Wave 4. Expect final Wave 5 push downward.',
                        'next_expected': 'Wave 5 (Final Push Down)',
                        'action_bias': 'SELL_PENDING'
                    }
            
            # Wave 3 (strongest move)
            elif len(pivots) >= 3:
                if types[-3:] == ['LOW', 'HIGH', 'LOW'] and current_price > pivots[-2]['price']:
                    return {
                        'wave': 'WAVE 3 (Strong Impulse)',
                        'confidence': 80,
                        'description': 'In powerful Wave 3 - strongest and longest wave. High momentum expected.',
                        'next_expected': 'Wave 4 (Correction)',
                        'action_bias': 'BUY'
                    }
                elif types[-3:] == ['HIGH', 'LOW', 'HIGH'] and current_price < pivots[-2]['price']:
                    return {
                        'wave': 'WAVE 3 (Strong Impulse Down)',
                        'confidence': 80,
                        'description': 'In powerful downward Wave 3. Strong selling pressure.',
                        'next_expected': 'Wave 4 (Bounce)',
                        'action_bias': 'SELL'
                    }
        
        return {
            'wave': 'TRANSITIONAL',
            'confidence': 40,
            'description': 'Pattern not clearly defined. May be in corrective or early impulse phase.',
            'next_expected': 'Wait for clear pattern formation',
            'action_bias': 'HOLD'
        }


class RatioAnalyzer:
    """Comparative Ratio Analysis with Market Index"""
    
    @staticmethod
    def analyze_relative_strength(ticker: str, benchmark: str = "^NSEI") -> Dict:
        """Analyze ticker performance relative to benchmark"""
        
        try:
            # Add delay for rate limiting
            time.sleep(1.5)
            
            # Fetch both tickers
            stock_data = yf.Ticker(ticker).history(period='3mo', interval='1d')
            time.sleep(1.5)
            benchmark_data = yf.Ticker(benchmark).history(period='3mo', interval='1d')
            
            if stock_data.empty or benchmark_data.empty:
                return {
                    'relative_strength': 1.0,
                    'outperformance': 0,
                    'stock_return': 0,
                    'benchmark_return': 0,
                    'interpretation': 'Insufficient data for comparison'
                }
            
            # Calculate returns
            stock_return = ((stock_data['Close'].iloc[-1] - stock_data['Close'].iloc[0]) / 
                          stock_data['Close'].iloc[0]) * 100
            
            benchmark_return = ((benchmark_data['Close'].iloc[-1] - benchmark_data['Close'].iloc[0]) / 
                              benchmark_data['Close'].iloc[0]) * 100
            
            # Relative strength ratio
            relative_strength = stock_return / benchmark_return if benchmark_return != 0 else 1.0
            outperformance = stock_return - benchmark_return
            
            # Interpretation
            if relative_strength > 1.2:
                interpretation = f"STRONG OUTPERFORMER: Stock up {stock_return:.2f}% vs benchmark {benchmark_return:.2f}%. Shows strong relative strength - positive indicator."
            elif relative_strength > 1.0:
                interpretation = f"OUTPERFORMER: Stock up {stock_return:.2f}% vs benchmark {benchmark_return:.2f}%. Moderate relative strength."
            elif relative_strength > 0.8:
                interpretation = f"UNDERPERFORMER: Stock up {stock_return:.2f}% vs benchmark {benchmark_return:.2f}%. Lagging the market."
            else:
                interpretation = f"WEAK: Stock up {stock_return:.2f}% vs benchmark {benchmark_return:.2f}%. Significant underperformance - caution advised."
            
            return {
                'relative_strength': relative_strength,
                'outperformance': outperformance,
                'stock_return': stock_return,
                'benchmark_return': benchmark_return,
                'interpretation': interpretation
            }
            
        except Exception as e:
            return {
                'relative_strength': 1.0,
                'outperformance': 0,
                'stock_return': 0,
                'benchmark_return': 0,
                'interpretation': f'Error in ratio analysis: {str(e)}'
            }


class VolumeAnalyzer:
    """Volume Analysis for confirmation"""
    
    @staticmethod
    def analyze_volume(df: pd.DataFrame) -> Dict:
        """Analyze volume patterns and trends"""
        
        if 'Volume' not in df.columns or df['Volume'].sum() == 0:
            return {
                'available': False,
                'interpretation': 'Volume data not available for this instrument',
                'volume_trend': 'N/A',
                'volume_score': 0
            }
        
        latest = df.iloc[-1]
        volume_sma = df['Volume'].rolling(window=20).mean().iloc[-1]
        volume_ratio = latest['Volume'] / volume_sma if volume_sma > 0 else 1
        
        # Volume trend (increasing or decreasing)
        recent_volume = df['Volume'].iloc[-10:].mean()
        older_volume = df['Volume'].iloc[-20:-10].mean()
        volume_trend_pct = ((recent_volume - older_volume) / older_volume * 100) if older_volume > 0 else 0
        
        # Price-Volume relationship
        price_change = ((latest['Close'] - df['Close'].iloc[-2]) / df['Close'].iloc[-2]) * 100
        
        # Determine volume trend
        if volume_trend_pct > 20:
            volume_trend = "INCREASING"
        elif volume_trend_pct < -20:
            volume_trend = "DECREASING"
        else:
            volume_trend = "STABLE"
        
        # Volume score (contribution to signal)
        volume_score = 0
        interpretation = ""
        
        if volume_ratio > 1.5 and price_change > 0:
            volume_score = 1.5
            interpretation = f"BULLISH CONFIRMATION: High volume ({volume_ratio:.2f}x average) on up move. Strong buying pressure."
        elif volume_ratio > 1.5 and price_change < 0:
            volume_score = -1.5
            interpretation = f"BEARISH CONFIRMATION: High volume ({volume_ratio:.2f}x average) on down move. Strong selling pressure."
        elif volume_ratio < 0.5:
            volume_score = -0.5
            interpretation = f"LOW CONVICTION: Volume ({volume_ratio:.2f}x average) below normal. Move lacks conviction."
        else:
            interpretation = f"NORMAL VOLUME: Volume ({volume_ratio:.2f}x average) near average. No special signal."
        
        interpretation += f" Volume trend is {volume_trend} ({volume_trend_pct:+.1f}%)."
        
        return {
            'available': True,
            'volume_ratio': volume_ratio,
            'volume_trend': volume_trend,
            'volume_trend_pct': volume_trend_pct,
            'interpretation': interpretation,
            'volume_score': volume_score
        }



    """Analyzes which patterns/indicators the market is following most reliably"""
    
    @staticmethod
    def analyze_pattern_reliability(df: pd.DataFrame) -> Dict:
        """Test reliability of different patterns over recent history"""
        
        if len(df) < 100:
            return {
                'most_reliable': 'INSUFFICIENT_DATA',
                'reliability_scores': {},
                'recommendations': []
            }
        
        reliability_scores = {}
        
        # Test Elliott Wave reliability
        elliott_score = PatternReliabilityAnalyzer._test_elliott_wave_reliability(df)
        reliability_scores['Elliott Wave'] = elliott_score
        
        # Test Fibonacci reliability
        fib_score = PatternReliabilityAnalyzer._test_fibonacci_reliability(df)
        reliability_scores['Fibonacci'] = fib_score
        
        # Test Support/Resistance reliability
        sr_score = PatternReliabilityAnalyzer._test_support_resistance_reliability(df)
        reliability_scores['Support/Resistance'] = sr_score
        
        # Test Moving Average reliability
        ma_score = PatternReliabilityAnalyzer._test_moving_average_reliability(df)
        reliability_scores['Moving Averages'] = ma_score
        
        # Test RSI reliability
        rsi_score = PatternReliabilityAnalyzer._test_rsi_reliability(df)
        reliability_scores['RSI'] = rsi_score
        
        # Test MACD reliability
        macd_score = PatternReliabilityAnalyzer._test_macd_reliability(df)
        reliability_scores['MACD'] = macd_score
        
        # Find most reliable pattern
        most_reliable = max(reliability_scores, key=reliability_scores.get)
        
        # Generate recommendations based on reliability
        recommendations = []
        for pattern, score in sorted(reliability_scores.items(), key=lambda x: x[1], reverse=True):
            if score > 70:
                recommendations.append(f"âœ… {pattern}: HIGHLY RELIABLE ({score:.1f}%) - Primary indicator")
            elif score > 55:
                recommendations.append(f"âš ï¸ {pattern}: MODERATELY RELIABLE ({score:.1f}%) - Use with confirmation")
            else:
                recommendations.append(f"âŒ {pattern}: UNRELIABLE ({score:.1f}%) - Ignore or use cautiously")
        
        return {
            'most_reliable': most_reliable,
            'reliability_scores': reliability_scores,
            'recommendations': recommendations
        }
    
    @staticmethod
    def _test_elliott_wave_reliability(df: pd.DataFrame) -> float:
        """Test how well Elliott Wave predictions worked historically"""
        
        correct_predictions = 0
        total_predictions = 0
        
        for i in range(50, len(df) - 10, 5):
            window_df = df.iloc[:i]
            elliott = ElliottWaveAnalyzer.detect_elliott_wave(window_df)
            
            if elliott['confidence'] > 60:
                action_bias = elliott.get('action_bias', 'HOLD')
                future_price = df['Close'].iloc[i+10]
                current_price = df['Close'].iloc[i]
                
                if action_bias == 'BUY' and future_price > current_price:
                    correct_predictions += 1
                elif action_bias == 'SELL' and future_price < current_price:
                    correct_predictions += 1
                
                total_predictions += 1
        
        return (correct_predictions / total_predictions * 100) if total_predictions > 0 else 50
    
    @staticmethod
    def _test_fibonacci_reliability(df: pd.DataFrame) -> float:
        """Test how well Fibonacci levels acted as support/resistance"""
        
        bounces_at_fib = 0
        total_tests = 0
        
        for i in range(50, len(df) - 5, 5):
            window_df = df.iloc[:i]
            fib = FibonacciAnalyzer.calculate_fibonacci_levels(window_df)
            
            current_price = df['Close'].iloc[i]
            
            # Check if price bounced from nearby Fibonacci level
            for level_name, level_value in fib['levels'].items():
                if abs(current_price - level_value) / current_price < 0.01:  # Within 1%
                    # Check if price bounced in next 5 periods
                    future_prices = df['Close'].iloc[i+1:i+6]
                    
                    if fib['trend'] == 'UPTREND' and level_value < current_price:
                        # Support test
                        if future_prices.max() > current_price:
                            bounces_at_fib += 1
                    elif fib['trend'] == 'DOWNTREND' and level_value > current_price:
                        # Resistance test
                        if future_prices.min() < current_price:
                            bounces_at_fib += 1
                    
                    total_tests += 1
                    break
        
        return (bounces_at_fib / total_tests * 100) if total_tests > 0 else 50
    
    @staticmethod
    def _test_support_resistance_reliability(df: pd.DataFrame) -> float:
        """Test how well S/R levels held"""
        
        holds = 0
        tests = 0
        
        for i in range(50, len(df) - 5, 5):
            window_df = df.iloc[:i]
            sr = SupportResistanceAnalyzer.find_strong_levels(window_df)
            
            current_price = df['Close'].iloc[i]
            support = sr['support']
            resistance = sr['resistance']
            
            # Test support
            if abs(current_price - support) / current_price < 0.015:
                future_low = df['Low'].iloc[i+1:i+6].min()
                if future_low >= support * 0.98:  # Held within 2%
                    holds += 1
                tests += 1
            
            # Test resistance
            if abs(current_price - resistance) / current_price < 0.015:
                future_high = df['High'].iloc[i+1:i+6].max()
                if future_high <= resistance * 1.02:  # Held within 2%
                    holds += 1
                tests += 1
        
        return (holds / tests * 100) if tests > 0 else 50
    
    @staticmethod
    def _test_moving_average_reliability(df: pd.DataFrame) -> float:
        """Test MA crossover reliability"""
        
        correct_signals = 0
        total_signals = 0
        
        for i in range(50, len(df) - 10):
            if pd.notna(df['SMA_20'].iloc[i]) and pd.notna(df['SMA_50'].iloc[i]):
                prev_diff = df['SMA_20'].iloc[i-1] - df['SMA_50'].iloc[i-1]
                curr_diff = df['SMA_20'].iloc[i] - df['SMA_50'].iloc[i]
                
                # Bullish crossover
                if prev_diff <= 0 and curr_diff > 0:
                    future_price = df['Close'].iloc[i+10]
                    current_price = df['Close'].iloc[i]
                    if future_price > current_price:
                        correct_signals += 1
                    total_signals += 1
                
                # Bearish crossover
                elif prev_diff >= 0 and curr_diff < 0:
                    future_price = df['Close'].iloc[i+10]
                    current_price = df['Close'].iloc[i]
                    if future_price < current_price:
                        correct_signals += 1
                    total_signals += 1
        
        return (correct_signals / total_signals * 100) if total_signals > 0 else 50
    
    @staticmethod
    def _test_rsi_reliability(df: pd.DataFrame) -> float:
        """Test RSI signal reliability"""
        
        correct_signals = 0
        total_signals = 0
        
        for i in range(50, len(df) - 10):
            rsi = df['RSI'].iloc[i]
            
            if rsi < 30:  # Oversold
                future_price = df['Close'].iloc[i+10]
                current_price = df['Close'].iloc[i]
                if future_price > current_price:
                    correct_signals += 1
                total_signals += 1
            
            elif rsi > 70:  # Overbought
                future_price = df['Close'].iloc[i+10]
                current_price = df['Close'].iloc[i]
                if future_price < current_price:
                    correct_signals += 1
                total_signals += 1
        
        return (correct_signals / total_signals * 100) if total_signals > 0 else 50
    
    @staticmethod
    def _test_macd_reliability(df: pd.DataFrame) -> float:
        """Test MACD crossover reliability"""
        
        correct_signals = 0
        total_signals = 0
        
        for i in range(50, len(df) - 10):
            if pd.notna(df['MACD'].iloc[i]) and pd.notna(df['MACD_Signal'].iloc[i]):
                prev_diff = df['MACD'].iloc[i-1] - df['MACD_Signal'].iloc[i-1]
                curr_diff = df['MACD'].iloc[i] - df['MACD_Signal'].iloc[i]
                
                # Bullish crossover
                if prev_diff <= 0 and curr_diff > 0:
                    future_price = df['Close'].iloc[i+10]
                    current_price = df['Close'].iloc[i]
                    if future_price > current_price:
                        correct_signals += 1
                    total_signals += 1
                
                # Bearish crossover
                elif prev_diff >= 0 and curr_diff < 0:
                    future_price = df['Close'].iloc[i+10]
                    current_price = df['Close'].iloc[i]
                    if future_price < current_price:
                        correct_signals += 1
                    total_signals += 1
        
        return (correct_signals / total_signals * 100) if total_signals > 0 else 50



    """Fibonacci Retracement and Extension Analysis"""
    
    @staticmethod
    def calculate_fibonacci_levels(df: pd.DataFrame, lookback: int = 50) -> Dict:
        """Calculate Fibonacci retracement and extension levels"""
        
        if len(df) < lookback:
            lookback = len(df)
        
        recent_data = df.iloc[-lookback:]
        high = recent_data['High'].max()
        low = recent_data['Low'].min()
        diff = high - low
        
        current_price = df['Close'].iloc[-1]
        
        # Determine trend direction
        sma_20 = df['SMA_20'].iloc[-1]
        trend = "UPTREND" if current_price > sma_20 else "DOWNTREND"
        
        # Retracement levels (for pullbacks in trend)
        if trend == "UPTREND":
            fib_levels = {
                '0%': high,
                '23.6%': high - (diff * 0.236),
                '38.2%': high - (diff * 0.382),
                '50%': high - (diff * 0.50),
                '61.8%': high - (diff * 0.618),
                '78.6%': high - (diff * 0.786),
                '100%': low
            }
        else:  # DOWNTREND
            fib_levels = {
                '0%': low,
                '23.6%': low + (diff * 0.236),
                '38.2%': low + (diff * 0.382),
                '50%': low + (diff * 0.50),
                '61.8%': low + (diff * 0.618),
                '78.6%': low + (diff * 0.786),
                '100%': high
            }
        
        # Extension levels (for targets)
        if trend == "UPTREND":
            extensions = {
                '127.2%': high + (diff * 0.272),
                '161.8%': high + (diff * 0.618),
                '200%': high + diff,
                '261.8%': high + (diff * 1.618)
            }
        else:
            extensions = {
                '127.2%': low - (diff * 0.272),
                '161.8%': low - (diff * 0.618),
                '200%': low - diff,
                '261.8%': low - (diff * 1.618)
            }
        
        # Find nearest support/resistance
        nearest_support = None
        nearest_resistance = None
        min_dist_support = float('inf')
        min_dist_resistance = float('inf')
        
        for level_name, level_value in fib_levels.items():
            dist = abs(current_price - level_value)
            if level_value < current_price and dist < min_dist_support:
                nearest_support = (level_name, level_value)
                min_dist_support = dist
            elif level_value > current_price and dist < min_dist_resistance:
                nearest_resistance = (level_name, level_value)
                min_dist_resistance = dist
        
        return {
            'trend': trend,
            'levels': fib_levels,
            'extensions': extensions,
            'nearest_support': nearest_support,
            'nearest_resistance': nearest_resistance,
            'high': high,
            'low': low
        }


class RSIDivergenceAnalyzer:
    """RSI Divergence Detection"""
    
    @staticmethod
    def detect_divergence(df: pd.DataFrame, lookback: int = 20) -> Dict:
        """Detect bullish and bearish RSI divergences"""
        
        if len(df) < lookback:
            return {'type': 'NONE', 'strength': 0, 'description': 'Insufficient data'}
        
        recent_df = df.iloc[-lookback:].copy()
        prices = recent_df['Close'].values
        rsi = recent_df['RSI'].values
        
        # Find peaks and troughs in price
        price_peaks = []
        price_troughs = []
        
        for i in range(2, len(prices) - 2):
            # Peak
            if prices[i] > prices[i-1] and prices[i] > prices[i-2] and \
               prices[i] > prices[i+1] and prices[i] > prices[i+2]:
                price_peaks.append((i, prices[i]))
            
            # Trough
            if prices[i] < prices[i-1] and prices[i] < prices[i-2] and \
               prices[i] < prices[i+1] and prices[i] < prices[i+2]:
                price_troughs.append((i, prices[i]))
        
        # Bearish Divergence (price making higher highs, RSI making lower highs)
        if len(price_peaks) >= 2:
            last_peak_idx, last_peak_price = price_peaks[-1]
            prev_peak_idx, prev_peak_price = price_peaks[-2]
            
            if last_peak_price > prev_peak_price and rsi[last_peak_idx] < rsi[prev_peak_idx]:
                strength = abs(rsi[prev_peak_idx] - rsi[last_peak_idx])
                return {
                    'type': 'BEARISH',
                    'strength': strength,
                    'description': f'Price made higher high ({prev_peak_price:.2f} -> {last_peak_price:.2f}) but RSI made lower high ({rsi[prev_peak_idx]:.1f} -> {rsi[last_peak_idx]:.1f}). Indicates weakening momentum - potential reversal down.'
                }
        
        # Bullish Divergence (price making lower lows, RSI making higher lows)
        if len(price_troughs) >= 2:
            last_trough_idx, last_trough_price = price_troughs[-1]
            prev_trough_idx, prev_trough_price = price_troughs[-2]
            
            if last_trough_price < prev_trough_price and rsi[last_trough_idx] > rsi[prev_trough_idx]:
                strength = abs(rsi[last_trough_idx] - rsi[prev_trough_idx])
                return {
                    'type': 'BULLISH',
                    'strength': strength,
                    'description': f'Price made lower low ({prev_trough_price:.2f} -> {last_trough_price:.2f}) but RSI made higher low ({rsi[prev_trough_idx]:.1f} -> {rsi[last_trough_idx]:.1f}). Indicates strengthening momentum - potential reversal up.'
                }
        
        return {
            'type': 'NONE',
            'strength': 0,
            'description': 'No significant divergence detected'
        }


class ElliottWaveAnalyzer:
    """Elliott Wave Pattern Detection"""
    
    @staticmethod
    def detect_elliott_wave(df: pd.DataFrame, lookback: int = 50) -> Dict:
        """Detect Elliott Wave patterns and current wave position"""
        
        if len(df) < lookback:
            lookback = len(df)
        
        recent_df = df.iloc[-lookback:].copy()
        prices = recent_df['Close'].values
        
        # Find significant pivots (simplified wave detection)
        pivots = ElliottWaveAnalyzer._find_pivots(prices)
        
        if len(pivots) < 5:
            return {
                'wave': 'UNKNOWN',
                'confidence': 0,
                'description': 'Insufficient pivot points for Elliott Wave analysis',
                'next_expected': 'N/A'
            }
        
        # Analyze last 5 pivots for Elliott Wave pattern
        last_5_pivots = pivots[-5:]
        wave_pattern = ElliottWaveAnalyzer._identify_wave_pattern(last_5_pivots, prices)
        
        return wave_pattern
    
    @staticmethod
    def _find_pivots(prices: np.ndarray, order: int = 5) -> List:
        """Find pivot points (local maxima and minima)"""
        pivots = []
        
        for i in range(order, len(prices) - order):
            # Check for peak
            if all(prices[i] >= prices[i-j] for j in range(1, order+1)) and \
               all(prices[i] >= prices[i+j] for j in range(1, order+1)):
                pivots.append({'index': i, 'price': prices[i], 'type': 'HIGH'})
            
            # Check for trough
            elif all(prices[i] <= prices[i-j] for j in range(1, order+1)) and \
                 all(prices[i] <= prices[i+j] for j in range(1, order+1)):
                pivots.append({'index': i, 'price': prices[i], 'type': 'LOW'})
        
        return pivots
    
    @staticmethod
    def _identify_wave_pattern(pivots: List, prices: np.ndarray) -> Dict:
        """Identify Elliott Wave pattern from pivots"""
        
        # Impulse Wave Pattern (5 waves: 1-up, 2-down, 3-up, 4-down, 5-up)
        # Corrective Wave Pattern (3 waves: A-down, B-up, C-down)
        
        current_price = prices[-1]
        last_pivot = pivots[-1]
        
        # Simplified pattern detection
        if len(pivots) >= 5:
            # Check for impulse pattern
            types = [p['type'] for p in pivots[-5:]]
            
            # Upward impulse: LOW, HIGH, LOW, HIGH, LOW (current above last high)
            if types == ['LOW', 'HIGH', 'LOW', 'HIGH', 'LOW']:
                wave_5_target = pivots[-2]['price']  # Wave 3 high
                
                if current_price > wave_5_target:
                    return {
                        'wave': 'WAVE 5 (Final Impulse Up)',
                        'confidence': 75,
                        'description': 'In final upward wave. Expect completion soon followed by correction. Wave 5 often equals Wave 1 in length.',
                        'next_expected': 'Corrective Wave A (Downward)',
                        'action_bias': 'SELL'
                    }
                else:
                    return {
                        'wave': 'WAVE 4 (Correction)',
                        'confidence': 70,
                        'description': 'In corrective Wave 4. Expect final Wave 5 push upward. Wave 4 typically retraces 38.2% of Wave 3.',
                        'next_expected': 'Wave 5 (Final Push Up)',
                        'action_bias': 'BUY_PENDING'
                    }
            
            # Downward impulse: HIGH, LOW, HIGH, LOW, HIGH
            elif types == ['HIGH', 'LOW', 'HIGH', 'LOW', 'HIGH']:
                wave_5_target = pivots[-2]['price']  # Wave 3 low
                
                if current_price < wave_5_target:
                    return {
                        'wave': 'WAVE 5 (Final Impulse Down)',
                        'confidence': 75,
                        'description': 'In final downward wave. Expect completion soon followed by correction upward.',
                        'next_expected': 'Corrective Wave A (Upward)',
                        'action_bias': 'BUY'
                    }
                else:
                    return {
                        'wave': 'WAVE 4 (Correction)',
                        'confidence': 70,
                        'description': 'In corrective Wave 4. Expect final Wave 5 push downward.',
                        'next_expected': 'Wave 5 (Final Push Down)',
                        'action_bias': 'SELL_PENDING'
                    }
            
            # Wave 3 (strongest move)
            elif len(pivots) >= 3:
                if types[-3:] == ['LOW', 'HIGH', 'LOW'] and current_price > pivots[-2]['price']:
                    return {
                        'wave': 'WAVE 3 (Strong Impulse)',
                        'confidence': 80,
                        'description': 'In powerful Wave 3 - strongest and longest wave. High momentum expected.',
                        'next_expected': 'Wave 4 (Correction)',
                        'action_bias': 'BUY'
                    }
                elif types[-3:] == ['HIGH', 'LOW', 'HIGH'] and current_price < pivots[-2]['price']:
                    return {
                        'wave': 'WAVE 3 (Strong Impulse Down)',
                        'confidence': 80,
                        'description': 'In powerful downward Wave 3. Strong selling pressure.',
                        'next_expected': 'Wave 4 (Bounce)',
                        'action_bias': 'SELL'
                    }
        
        return {
            'wave': 'TRANSITIONAL',
            'confidence': 40,
            'description': 'Pattern not clearly defined. May be in corrective or early impulse phase.',
            'next_expected': 'Wait for clear pattern formation',
            'action_bias': 'HOLD'
        }


class RatioAnalyzer:
    """Comparative Ratio Analysis with Market Index"""
    
    @staticmethod
    def analyze_relative_strength(ticker: str, benchmark: str = "^NSEI") -> Dict:
        """Analyze ticker performance relative to benchmark"""
        
        try:
            # Fetch both tickers
            stock_data = yf.Ticker(ticker).history(period='3mo', interval='1d')
            benchmark_data = yf.Ticker(benchmark).history(period='3mo', interval='1d')
            
            if stock_data.empty or benchmark_data.empty:
                return {
                    'relative_strength': 1.0,
                    'outperformance': 0,
                    'interpretation': 'Insufficient data for comparison'
                }
            
            # Calculate returns
            stock_return = ((stock_data['Close'].iloc[-1] - stock_data['Close'].iloc[0]) / 
                          stock_data['Close'].iloc[0]) * 100
            
            benchmark_return = ((benchmark_data['Close'].iloc[-1] - benchmark_data['Close'].iloc[0]) / 
                              benchmark_data['Close'].iloc[0]) * 100
            
            # Relative strength ratio
            relative_strength = stock_return / benchmark_return if benchmark_return != 0 else 1.0
            outperformance = stock_return - benchmark_return
            
            # Interpretation
            if relative_strength > 1.2:
                interpretation = f"STRONG OUTPERFORMER: Stock up {stock_return:.2f}% vs benchmark {benchmark_return:.2f}%. Shows strong relative strength - positive indicator."
            elif relative_strength > 1.0:
                interpretation = f"OUTPERFORMER: Stock up {stock_return:.2f}% vs benchmark {benchmark_return:.2f}%. Moderate relative strength."
            elif relative_strength > 0.8:
                interpretation = f"UNDERPERFORMER: Stock up {stock_return:.2f}% vs benchmark {benchmark_return:.2f}%. Lagging the market."
            else:
                interpretation = f"WEAK: Stock up {stock_return:.2f}% vs benchmark {benchmark_return:.2f}%. Significant underperformance - caution advised."
            
            return {
                'relative_strength': relative_strength,
                'outperformance': outperformance,
                'stock_return': stock_return,
                'benchmark_return': benchmark_return,
                'interpretation': interpretation
            }
            
        except Exception as e:
            return {
                'relative_strength': 1.0,
                'outperformance': 0,
                'interpretation': f'Error in ratio analysis: {str(e)}'
            }

    """Z-Score Analysis for Mean Reversion and Extreme Conditions"""
    
    @staticmethod
    def calculate_zscore(df: pd.DataFrame, window: int = 20) -> Dict:
        """Calculate Z-Score and interpret its impact"""
        
        if len(df) < window:
            return {
                'current_zscore': 0,
                'interpretation': 'Insufficient data',
                'historical_impact': 'N/A',
                'future_outlook': 'N/A'
            }
        
        # Calculate rolling Z-Score
        close_prices = df['Close']
        rolling_mean = close_prices.rolling(window=window).mean()
        rolling_std = close_prices.rolling(window=window).std()
        
        zscore = (close_prices - rolling_mean) / rolling_std
        df['ZScore'] = zscore
        
        current_zscore = zscore.iloc[-1]
        
        # Historical analysis
        historical_analysis = ZScoreAnalyzer._analyze_historical_zscore(df, window)
        
        # Current interpretation
        if current_zscore > 2:
            interpretation = "EXTREMELY OVERBOUGHT"
            signal = "Strong mean reversion expected - consider selling"
        elif current_zscore > 1.5:
            interpretation = "OVERBOUGHT"
            signal = "Price extended above mean - potential pullback"
        elif current_zscore > 1:
            interpretation = "MODERATELY OVERBOUGHT"
            signal = "Price above average - watch for reversal"
        elif current_zscore < -2:
            interpretation = "EXTREMELY OVERSOLD"
            signal = "Strong mean reversion expected - consider buying"
        elif current_zscore < -1.5:
            interpretation = "OVERSOLD"
            signal = "Price extended below mean - potential bounce"
        elif current_zscore < -1:
            interpretation = "MODERATELY OVERSOLD"
            signal = "Price below average - watch for recovery"
        else:
            interpretation = "NEUTRAL"
            signal = "Price near historical average - no extreme condition"
        
        # Future outlook
        future_outlook = ZScoreAnalyzer._forecast_based_on_zscore(
            current_zscore, historical_analysis
        )
        
        return {
            'current_zscore': current_zscore,
            'interpretation': f"{interpretation} (Z={current_zscore:.2f})",
            'signal': signal,
            'historical_impact': historical_analysis,
            'future_outlook': future_outlook
        }
    
    @staticmethod
    def _analyze_historical_zscore(df: pd.DataFrame, window: int) -> str:
        """Analyze how Z-Score behaved historically"""
        
        zscore = df['ZScore'].dropna()
        
        if len(zscore) < 50:
            return "Limited historical data for Z-Score analysis"
        
        # Count extreme events
        extreme_high = (zscore > 2).sum()
        extreme_low = (zscore < -2).sum()
        
        # Check mean reversion success rate
        reversion_success = 0
        total_extremes = 0
        
        for i in range(len(zscore) - 10):
            if zscore.iloc[i] > 2:  # Overbought
                # Check if price reverted in next 10 periods
                future_prices = df['Close'].iloc[i+1:i+11]
                if future_prices.min() < df['Close'].iloc[i]:
                    reversion_success += 1
                total_extremes += 1
            
            elif zscore.iloc[i] < -2:  # Oversold
                future_prices = df['Close'].iloc[i+1:i+11]
                if future_prices.max() > df['Close'].iloc[i]:
                    reversion_success += 1
                total_extremes += 1
        
        success_rate = (reversion_success / total_extremes * 100) if total_extremes > 0 else 0
        
        analysis = f"Historical Z-Score analysis: {extreme_high} overbought events, "
        analysis += f"{extreme_low} oversold events. Mean reversion success rate: {success_rate:.1f}%. "
        
        if success_rate > 70:
            analysis += "Strong historical tendency to revert to mean."
        elif success_rate > 50:
            analysis += "Moderate mean reversion tendency."
        else:
            analysis += "Weak mean reversion - trending market."
        
        return analysis
    
    @staticmethod
    def _forecast_based_on_zscore(current_zscore: float, historical: str) -> str:
        """Forecast future price movement based on Z-Score"""
        
        if current_zscore > 2:
            forecast = "HIGH PROBABILITY of price decline in coming sessions. "
            forecast += "Z-Score above 2 indicates extreme deviation from mean. "
            forecast += "Historical data suggests mean reversion is likely. "
            forecast += "Consider taking profits or waiting for pullback before entering longs."
        
        elif current_zscore > 1:
            forecast = "MODERATE PROBABILITY of consolidation or mild pullback. "
            forecast += "Price is stretched but not at extreme levels. "
            forecast += "Could continue higher with momentum, but risk/reward favors caution."
        
        elif current_zscore < -2:
            forecast = "HIGH PROBABILITY of price recovery in coming sessions. "
            forecast += "Z-Score below -2 indicates extreme undervaluation relative to recent mean. "
            forecast += "Historical patterns suggest strong bounce potential. "
            forecast += "Risk/reward favors buying at these oversold levels."
        
        elif current_zscore < -1:
            forecast = "MODERATE PROBABILITY of upward move. "
            forecast += "Price below average presents opportunity. "
            forecast += "Could decline further, but statistical edge favors buyers."
        
        else:
            forecast = "NEUTRAL OUTLOOK - Price near equilibrium. "
            forecast += "No statistical edge from Z-Score. "
            forecast += "Rely on trend, momentum, and other technical indicators."
        
        return forecast
    """Advanced Technical Analysis Engine"""
    
    @staticmethod
    def calculate_indicators(df: pd.DataFrame) -> pd.DataFrame:
        """Calculate comprehensive technical indicators"""
        df = df.copy()
        
        # Moving Averages
        df['SMA_20'] = df['Close'].rolling(window=20).mean()
        df['SMA_50'] = df['Close'].rolling(window=50).mean()
        df['SMA_200'] = df['Close'].rolling(window=200).mean()
        df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()
        df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()
        
        # MACD
        df['MACD'] = df['EMA_12'] - df['EMA_26']
        df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
        df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']
        
        # RSI
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # Bollinger Bands
        df['BB_Middle'] = df['Close'].rolling(window=20).mean()
        bb_std = df['Close'].rolling(window=20).std()
        df['BB_Upper'] = df['BB_Middle'] + (bb_std * 2)
        df['BB_Lower'] = df['BB_Middle'] - (bb_std * 2)
        
        # ATR (Average True Range)
        high_low = df['High'] - df['Low']
        high_close = np.abs(df['High'] - df['Close'].shift())
        low_close = np.abs(df['Low'] - df['Close'].shift())
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = np.max(ranges, axis=1)
        df['ATR'] = true_range.rolling(14).mean()
        
        # Stochastic Oscillator
        low_14 = df['Low'].rolling(window=14).min()
        high_14 = df['High'].rolling(window=14).max()
        df['Stoch_K'] = 100 * ((df['Close'] - low_14) / (high_14 - low_14))
        df['Stoch_D'] = df['Stoch_K'].rolling(window=3).mean()
        
        # ADX (Average Directional Index)
        df['ADX'] = TechnicalAnalyzer.calculate_adx(df)
        
        # Volume indicators
        df['Volume_SMA'] = df['Volume'].rolling(window=20).mean()
        df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA']
        
        # Support and Resistance
        df['Support'] = df['Low'].rolling(window=20).min()
        df['Resistance'] = df['High'].rolling(window=20).max()
        
        return df
    
    @staticmethod
    def calculate_adx(df: pd.DataFrame, period: int = 14) -> pd.Series:
        """Calculate Average Directional Index"""
        high = df['High']
        low = df['Low']
        close = df['Close']
        
        plus_dm = high.diff()
        minus_dm = -low.diff()
        plus_dm[plus_dm < 0] = 0
        minus_dm[minus_dm < 0] = 0
        
        tr = pd.DataFrame({
            'hl': high - low,
            'hc': abs(high - close.shift()),
            'lc': abs(low - close.shift())
        }).max(axis=1)
        
        atr = tr.rolling(window=period).mean()
        plus_di = 100 * (plus_dm.rolling(window=period).mean() / atr)
        minus_di = 100 * (minus_dm.rolling(window=period).mean() / atr)
        
        dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di)
        adx = dx.rolling(window=period).mean()
        
        return adx

class VolumeAnalyzer:
    """Volume Analysis for confirmation"""
    
    @staticmethod
    def analyze_volume(df: pd.DataFrame) -> Dict:
        """Analyze volume patterns and trends"""
        
        if 'Volume' not in df.columns or df['Volume'].sum() == 0:
            return {
                'available': False,
                'interpretation': 'Volume data not available for this instrument',
                'volume_trend': 'N/A',
                'volume_score': 0
            }
        
        latest = df.iloc[-1]
        volume_sma = df['Volume'].rolling(window=20).mean().iloc[-1]
        volume_ratio = latest['Volume'] / volume_sma if volume_sma > 0 else 1
        
        # Volume trend (increasing or decreasing)
        recent_volume = df['Volume'].iloc[-10:].mean()
        older_volume = df['Volume'].iloc[-20:-10].mean()
        volume_trend_pct = ((recent_volume - older_volume) / older_volume * 100) if older_volume > 0 else 0
        
        # Price-Volume relationship
        price_change = ((latest['Close'] - df['Close'].iloc[-2]) / df['Close'].iloc[-2]) * 100
        
        # Determine volume trend
        if volume_trend_pct > 20:
            volume_trend = "INCREASING"
        elif volume_trend_pct < -20:
            volume_trend = "DECREASING"
        else:
            volume_trend = "STABLE"
        
        # Volume score (contribution to signal)
        volume_score = 0
        interpretation = ""
        
        if volume_ratio > 1.5 and price_change > 0:
            volume_score = 1.5
            interpretation = f"BULLISH CONFIRMATION: High volume ({volume_ratio:.2f}x average) on up move. Strong buying pressure."
        elif volume_ratio > 1.5 and price_change < 0:
            volume_score = -1.5
            interpretation = f"BEARISH CONFIRMATION: High volume ({volume_ratio:.2f}x average) on down move. Strong selling pressure."
        elif volume_ratio < 0.5:
            volume_score = -0.5
            interpretation = f"LOW CONVICTION: Volume ({volume_ratio:.2f}x average) below normal. Move lacks conviction."
        else:
            interpretation = f"NORMAL VOLUME: Volume ({volume_ratio:.2f}x average) near average. No special signal."
        
        interpretation += f" Volume trend is {volume_trend} ({volume_trend_pct:+.1f}%)."
        
        return {
            'available': True,
            'volume_ratio': volume_ratio,
            'volume_trend': volume_trend,
            'volume_trend_pct': volume_trend_pct,
            'interpretation': interpretation,
            'volume_score': volume_score
        }


class PatternReliabilityAnalyzer:
    """Analyzes which patterns/indicators the market is following most reliably"""
    
    @staticmethod
    def analyze_pattern_reliability(df: pd.DataFrame) -> Dict:
        """Test reliability of different patterns over recent history"""
        
        if len(df) < 100:
            return {
                'most_reliable': 'INSUFFICIENT_DATA',
                'reliability_scores': {},
                'recommendations': []
            }
        
        reliability_scores = {}
        
        # Test Elliott Wave reliability
        elliott_score = PatternReliabilityAnalyzer._test_elliott_wave_reliability(df)
        reliability_scores['Elliott Wave'] = elliott_score
        
        # Test Fibonacci reliability
        fib_score = PatternReliabilityAnalyzer._test_fibonacci_reliability(df)
        reliability_scores['Fibonacci'] = fib_score
        
        # Test Support/Resistance reliability
        sr_score = PatternReliabilityAnalyzer._test_support_resistance_reliability(df)
        reliability_scores['Support/Resistance'] = sr_score
        
        # Test Moving Average reliability
        ma_score = PatternReliabilityAnalyzer._test_moving_average_reliability(df)
        reliability_scores['Moving Averages'] = ma_score
        
        # Test RSI reliability
        rsi_score = PatternReliabilityAnalyzer._test_rsi_reliability(df)
        reliability_scores['RSI'] = rsi_score
        
        # Test MACD reliability
        macd_score = PatternReliabilityAnalyzer._test_macd_reliability(df)
        reliability_scores['MACD'] = macd_score
        
        # Find most reliable pattern
        most_reliable = max(reliability_scores, key=reliability_scores.get)
        
        # Generate recommendations based on reliability
        recommendations = []
        for pattern, score in sorted(reliability_scores.items(), key=lambda x: x[1], reverse=True):
            if score > 70:
                recommendations.append(f"âœ… {pattern}: HIGHLY RELIABLE ({score:.1f}%) - Primary indicator")
            elif score > 55:
                recommendations.append(f"âš ï¸ {pattern}: MODERATELY RELIABLE ({score:.1f}%) - Use with confirmation")
            else:
                recommendations.append(f"âŒ {pattern}: UNRELIABLE ({score:.1f}%) - Ignore or use cautiously")
        
        return {
            'most_reliable': most_reliable,
            'reliability_scores': reliability_scores,
            'recommendations': recommendations
        }
    
    @staticmethod
    def _test_elliott_wave_reliability(df: pd.DataFrame) -> float:
        """Test how well Elliott Wave predictions worked historically"""
        
        correct_predictions = 0
        total_predictions = 0
        
        for i in range(50, len(df) - 10, 5):
            window_df = df.iloc[:i]
            elliott = ElliottWaveAnalyzer.detect_elliott_wave(window_df)
            
            if elliott['confidence'] > 60:
                action_bias = elliott.get('action_bias', 'HOLD')
                future_price = df['Close'].iloc[i+10]
                current_price = df['Close'].iloc[i]
                
                if action_bias == 'BUY' and future_price > current_price:
                    correct_predictions += 1
                elif action_bias == 'SELL' and future_price < current_price:
                    correct_predictions += 1
                
                total_predictions += 1
        
        return (correct_predictions / total_predictions * 100) if total_predictions > 0 else 50
    
    @staticmethod
    def _test_fibonacci_reliability(df: pd.DataFrame) -> float:
        """Test how well Fibonacci levels acted as support/resistance"""
        
        bounces_at_fib = 0
        total_tests = 0
        
        for i in range(50, len(df) - 5, 5):
            window_df = df.iloc[:i]
            fib = FibonacciAnalyzer.calculate_fibonacci_levels(window_df)
            
            current_price = df['Close'].iloc[i]
            
            # Check if price bounced from nearby Fibonacci level
            for level_name, level_value in fib['levels'].items():
                if abs(current_price - level_value) / current_price < 0.01:  # Within 1%
                    # Check if price bounced in next 5 periods
                    future_prices = df['Close'].iloc[i+1:i+6]
                    
                    if fib['trend'] == 'UPTREND' and level_value < current_price:
                        # Support test
                        if future_prices.max() > current_price:
                            bounces_at_fib += 1
                    elif fib['trend'] == 'DOWNTREND' and level_value > current_price:
                        # Resistance test
                        if future_prices.min() < current_price:
                            bounces_at_fib += 1
                    
                    total_tests += 1
                    break
        
        return (bounces_at_fib / total_tests * 100) if total_tests > 0 else 50
    
    @staticmethod
    def _test_support_resistance_reliability(df: pd.DataFrame) -> float:
        """Test how well S/R levels held"""
        
        holds = 0
        tests = 0
        
        for i in range(50, len(df) - 5, 5):
            window_df = df.iloc[:i]
            sr = SupportResistanceAnalyzer.find_strong_levels(window_df)
            
            current_price = df['Close'].iloc[i]
            support = sr['support']
            resistance = sr['resistance']
            
            # Test support
            if abs(current_price - support) / current_price < 0.015:
                future_low = df['Low'].iloc[i+1:i+6].min()
                if future_low >= support * 0.98:  # Held within 2%
                    holds += 1
                tests += 1
            
            # Test resistance
            if abs(current_price - resistance) / current_price < 0.015:
                future_high = df['High'].iloc[i+1:i+6].max()
                if future_high <= resistance * 1.02:  # Held within 2%
                    holds += 1
                tests += 1
        
        return (holds / tests * 100) if tests > 0 else 50
    
    @staticmethod
    def _test_moving_average_reliability(df: pd.DataFrame) -> float:
        """Test MA crossover reliability"""
        
        correct_signals = 0
        total_signals = 0
        
        for i in range(50, len(df) - 10):
            if pd.notna(df['SMA_20'].iloc[i]) and pd.notna(df['SMA_50'].iloc[i]):
                prev_diff = df['SMA_20'].iloc[i-1] - df['SMA_50'].iloc[i-1]
                curr_diff = df['SMA_20'].iloc[i] - df['SMA_50'].iloc[i]
                
                # Bullish crossover
                if prev_diff <= 0 and curr_diff > 0:
                    future_price = df['Close'].iloc[i+10]
                    current_price = df['Close'].iloc[i]
                    if future_price > current_price:
                        correct_signals += 1
                    total_signals += 1
                
                # Bearish crossover
                elif prev_diff >= 0 and curr_diff < 0:
                    future_price = df['Close'].iloc[i+10]
                    current_price = df['Close'].iloc[i]
                    if future_price < current_price:
                        correct_signals += 1
                    total_signals += 1
        
        return (correct_signals / total_signals * 100) if total_signals > 0 else 50
    
    @staticmethod
    def _test_rsi_reliability(df: pd.DataFrame) -> float:
        """Test RSI signal reliability"""
        
        correct_signals = 0
        total_signals = 0
        
        for i in range(50, len(df) - 10):
            rsi = df['RSI'].iloc[i]
            
            if rsi < 30:  # Oversold
                future_price = df['Close'].iloc[i+10]
                current_price = df['Close'].iloc[i]
                if future_price > current_price:
                    correct_signals += 1
                total_signals += 1
            
            elif rsi > 70:  # Overbought
                future_price = df['Close'].iloc[i+10]
                current_price = df['Close'].iloc[i]
                if future_price < current_price:
                    correct_signals += 1
                total_signals += 1
        
        return (correct_signals / total_signals * 100) if total_signals > 0 else 50
    
    @staticmethod
    def _test_macd_reliability(df: pd.DataFrame) -> float:
        """Test MACD crossover reliability"""
        
        correct_signals = 0
        total_signals = 0
        
        for i in range(50, len(df) - 10):
            if pd.notna(df['MACD'].iloc[i]) and pd.notna(df['MACD_Signal'].iloc[i]):
                prev_diff = df['MACD'].iloc[i-1] - df['MACD_Signal'].iloc[i-1]
                curr_diff = df['MACD'].iloc[i] - df['MACD_Signal'].iloc[i]
                
                # Bullish crossover
                if prev_diff <= 0 and curr_diff > 0:
                    future_price = df['Close'].iloc[i+10]
                    current_price = df['Close'].iloc[i]
                    if future_price > current_price:
                        correct_signals += 1
                    total_signals += 1
                
                # Bearish crossover
                elif prev_diff >= 0 and curr_diff < 0:
                    future_price = df['Close'].iloc[i+10]
                    current_price = df['Close'].iloc[i]
                    if future_price < current_price:
                        correct_signals += 1
                    total_signals += 1
        
        return (correct_signals / total_signals * 100) if total_signals > 0 else 50


class StrategyEngine:
    """Multi-Strategy Trading Engine"""
    
    def __init__(self):
        self.strategies = {
            'trend_following': self.trend_following_strategy,
            'mean_reversion': self.mean_reversion_strategy,
            'momentum': self.momentum_strategy,
            'breakout': self.breakout_strategy,
            'scalping': self.scalping_strategy
        }
    
    def analyze_multiple_timeframes(self, ticker: str, period: str, 
                                   trading_style: str) -> Dict:
        """Analyze multiple timeframes and generate signals"""
        
        timeframe_map = {
            'Scalping': ['1m', '5m', '15m'],
            'Day Trading': ['5m', '15m', '1h'],
            'Swing Trading': ['1h', '4h', '1d'],
            'Positional Trading': ['1d', '1d', '1d']  # Same for all
        }
        
        timeframes = timeframe_map.get(trading_style, ['15m', '1h', '4h'])
        timeframe_results = {}
        
        for tf in timeframes:
            try:
                time.sleep(1.5)  # Rate limiting
                df = DataFetcher.fetch_data(ticker, period, tf)
                
                if df.empty:
                    continue
                
                df = TechnicalAnalyzer.calculate_indicators(df)
                market_structure = self.detect_market_structure(df)
                strategy = self.select_best_strategy(df, trading_style)
                result = self.strategies[strategy](df)
                
                # Determine signal
                score = result['score']
                if score > 2:
                    signal = "BUY"
                elif score < -2:
                    signal = "SELL"
                else:
                    signal = "HOLD"
                
                timeframe_results[tf] = {
                    'signal': signal,
                    'score': score,
                    'strategy': strategy,
                    'market_structure': market_structure,
                    'signals_list': result['signals'][:3]  # Top 3 signals
                }
                
            except Exception as e:
                continue
        
        return timeframe_results
    
    def detect_market_structure(self, df: pd.DataFrame) -> str:
        """Detect current market structure"""
        if len(df) < 50:
            return 'ranging'
        
        latest = df.iloc[-1]
        sma_20 = latest['SMA_20']
        sma_50 = latest['SMA_50']
        adx = latest['ADX']
        atr = latest['ATR']
        close = latest['Close']
        
        # Volatility measure
        volatility = (atr / close) * 100
        
        # Trend strength
        if adx > 25 and sma_20 > sma_50:
            if volatility > 2:
                return 'strong_uptrend'
            return 'uptrend'
        elif adx > 25 and sma_20 < sma_50:
            if volatility > 2:
                return 'strong_downtrend'
            return 'downtrend'
        elif adx < 20:
            return 'ranging'
        else:
            return 'ranging'
    
    def select_best_strategy(self, df: pd.DataFrame, trading_style: str) -> str:
        """Select optimal strategy based on market structure"""
        market_structure = self.detect_market_structure(df)
        
        # Strategy selection based on market and trading style
        if trading_style == "Scalping":
            return 'scalping'
        elif trading_style == "Day Trading":
            if market_structure in ['strong_uptrend', 'strong_downtrend']:
                return 'momentum'
            elif market_structure == 'ranging':
                return 'mean_reversion'
            else:
                return 'breakout'
        elif trading_style == "Swing Trading":
            if market_structure in ['uptrend', 'downtrend']:
                return 'trend_following'
            else:
                return 'breakout'
        else:  # Positional
            return 'trend_following'
    
    def trend_following_strategy(self, df: pd.DataFrame) -> Dict:
        """Trend Following Strategy"""
        latest = df.iloc[-1]
        prev = df.iloc[-2]
        
        score = 0
        signals = []
        
        # Moving Average Alignment
        if latest['SMA_20'] > latest['SMA_50'] > latest['SMA_200']:
            score += 2
            signals.append("Strong upward MA alignment")
        elif latest['SMA_20'] < latest['SMA_50'] < latest['SMA_200']:
            score -= 2
            signals.append("Strong downward MA alignment")
        
        # MACD
        if latest['MACD'] > latest['MACD_Signal'] and prev['MACD'] <= prev['MACD_Signal']:
            score += 1.5
            signals.append("MACD bullish crossover")
        elif latest['MACD'] < latest['MACD_Signal'] and prev['MACD'] >= prev['MACD_Signal']:
            score -= 1.5
            signals.append("MACD bearish crossover")
        
        # ADX Trend Strength
        if latest['ADX'] > 25:
            signals.append(f"Strong trend (ADX: {latest['ADX']:.1f})")
            score = score * 1.2 if score != 0 else score
        
        # Price vs SMA
        if latest['Close'] > latest['SMA_20']:
            score += 0.5
        else:
            score -= 0.5
        
        return {'score': score, 'signals': signals}
    
    def mean_reversion_strategy(self, df: pd.DataFrame) -> Dict:
        """Mean Reversion Strategy"""
        latest = df.iloc[-1]
        score = 0
        signals = []
        
        # Bollinger Bands
        if latest['Close'] < latest['BB_Lower']:
            score += 2
            signals.append("Price below lower BB - oversold")
        elif latest['Close'] > latest['BB_Upper']:
            score -= 2
            signals.append("Price above upper BB - overbought")
        
        # RSI
        if latest['RSI'] < 30:
            score += 1.5
            signals.append(f"RSI oversold ({latest['RSI']:.1f})")
        elif latest['RSI'] > 70:
            score -= 1.5
            signals.append(f"RSI overbought ({latest['RSI']:.1f})")
        
        # Stochastic
        if latest['Stoch_K'] < 20:
            score += 1
            signals.append("Stochastic oversold")
        elif latest['Stoch_K'] > 80:
            score -= 1
            signals.append("Stochastic overbought")
        
        return {'score': score, 'signals': signals}
    
    def momentum_strategy(self, df: pd.DataFrame) -> Dict:
        """Momentum Strategy"""
        latest = df.iloc[-1]
        prev = df.iloc[-2]
        score = 0
        signals = []
        
        # RSI Momentum
        if 50 < latest['RSI'] < 70:
            score += 1.5
            signals.append("Bullish RSI momentum zone")
        elif 30 < latest['RSI'] < 50:
            score -= 1.5
            signals.append("Bearish RSI momentum zone")
        
        # MACD Histogram
        if latest['MACD_Hist'] > prev['MACD_Hist'] > 0:
            score += 1
            signals.append("Increasing bullish MACD histogram")
        elif latest['MACD_Hist'] < prev['MACD_Hist'] < 0:
            score -= 1
            signals.append("Increasing bearish MACD histogram")
        
        # Volume
        if latest['Volume_Ratio'] > 1.5:
            signals.append("High volume confirmation")
            score = score * 1.3 if score != 0 else score
        
        # Price momentum
        price_change = (latest['Close'] - prev['Close']) / prev['Close'] * 100
        if price_change > 1:
            score += 1
            signals.append(f"Strong upward momentum ({price_change:.2f}%)")
        elif price_change < -1:
            score -= 1
            signals.append(f"Strong downward momentum ({price_change:.2f}%)")
        
        return {'score': score, 'signals': signals}
    
    def breakout_strategy(self, df: pd.DataFrame) -> Dict:
        """Breakout Strategy"""
        latest = df.iloc[-1]
        prev = df.iloc[-2]
        score = 0
        signals = []
        
        # Resistance breakout
        if latest['Close'] > latest['Resistance'] and prev['Close'] <= prev['Resistance']:
            score += 2.5
            signals.append("Bullish resistance breakout")
        
        # Support breakdown
        if latest['Close'] < latest['Support'] and prev['Close'] >= prev['Support']:
            score -= 2.5
            signals.append("Bearish support breakdown")
        
        # Volume confirmation
        if latest['Volume_Ratio'] > 1.5:
            signals.append("Breakout with high volume")
            score = score * 1.4 if score != 0 else score
        
        # ATR expansion
        if len(df) > 20:
            atr_avg = df['ATR'].iloc[-20:-1].mean()
            if latest['ATR'] > atr_avg * 1.2:
                signals.append("Volatility expansion")
                score = score * 1.2 if score != 0 else score
        
        return {'score': score, 'signals': signals}
    
    def scalping_strategy(self, df: pd.DataFrame) -> Dict:
        """Scalping Strategy - Quick entries/exits"""
        latest = df.iloc[-1]
        prev = df.iloc[-2]
        score = 0
        signals = []
        
        # Quick EMA crossovers
        if latest['EMA_12'] > latest['EMA_26'] and prev['EMA_12'] <= prev['EMA_26']:
            score += 2
            signals.append("Fast EMA crossover - bullish")
        elif latest['EMA_12'] < latest['EMA_26'] and prev['EMA_12'] >= prev['EMA_26']:
            score -= 2
            signals.append("Fast EMA crossover - bearish")
        
        # Stochastic quick signals
        if latest['Stoch_K'] < 30 and latest['Stoch_K'] > prev['Stoch_K']:
            score += 1.5
            signals.append("Stochastic turning up from oversold")
        elif latest['Stoch_K'] > 70 and latest['Stoch_K'] < prev['Stoch_K']:
            score -= 1.5
            signals.append("Stochastic turning down from overbought")
        
        # Tight price action
        bb_width = (latest['BB_Upper'] - latest['BB_Lower']) / latest['BB_Middle']
        if bb_width < 0.02:
            signals.append("Tight consolidation - breakout pending")
        
        return {'score': score, 'signals': signals}
    
    def generate_signal(self, df: pd.DataFrame, strategy_name: str, 
                       trading_style: str, ticker: str, 
                       timeframe_signals: Dict = None,
                       ratio_ticker: str = None) -> TradingSignal:
        """Generate final trading signal with comprehensive analysis and pattern reliability"""
        
        # Execute strategy
        strategy_func = self.strategies[strategy_name]
        result = strategy_func(df)
        
        score = result['score']
        signals = result['signals']
        
        latest = df.iloc[-1]
        atr = latest['ATR']
        close = latest['Close']
        
        # CRITICAL: Analyze which patterns market is following reliably
        pattern_reliability = PatternReliabilityAnalyzer.analyze_pattern_reliability(df)
        most_reliable_pattern = pattern_reliability['most_reliable']
        reliability_scores = pattern_reliability['reliability_scores']
        
        # Sentiment Analysis
        sentiment_analyzer = SentimentAnalyzer(ticker)
        sentiment_result = sentiment_analyzer.analyze()
        
        # Support/Resistance Analysis
        sr_analysis = SupportResistanceAnalyzer.find_strong_levels(df)
        
        # Z-Score Analysis
        zscore_analysis = ZScoreAnalyzer.calculate_zscore(df)
        
        # Fibonacci Analysis
        fib_analysis = FibonacciAnalyzer.calculate_fibonacci_levels(df)
        
        # RSI Divergence
        divergence = RSIDivergenceAnalyzer.detect_divergence(df)
        
        # Elliott Wave Analysis
        elliott_wave = ElliottWaveAnalyzer.detect_elliott_wave(df)
        
        # Ratio Analysis (use provided ticker or default)
        if ratio_ticker:
            benchmark = ratio_ticker
        else:
            benchmark = "^NSEI" if ticker.endswith(".NS") or ticker.endswith(".BO") else "^NSEI"
        
        ratio_analysis = RatioAnalyzer.analyze_relative_strength(ticker, benchmark)
        
        # Volume Analysis
        volume_analysis = VolumeAnalyzer.analyze_volume(df)
        
        # Adjust score based on all factors WITH RELIABILITY WEIGHTING
        adjusted_score = score
        
        # Sentiment adjustment
        adjusted_score += sentiment_result['score'] * 1.5
        
        # Volume adjustment (if available)
        if volume_analysis['available']:
            adjusted_score += volume_analysis['volume_score']
        
        # Z-Score adjustment
        zscore = zscore_analysis['current_zscore']
        if zscore > 2:
            adjusted_score -= 1.5
        elif zscore < -2:
            adjusted_score += 1.5
        
        # Elliott Wave adjustment (weighted by reliability)
        elliott_reliability = reliability_scores.get('Elliott Wave', 50) / 100
        wave_bias = elliott_wave.get('action_bias', 'HOLD')
        if wave_bias == 'BUY':
            adjusted_score += 1.5 * elliott_reliability
        elif wave_bias == 'SELL':
            adjusted_score -= 1.5 * elliott_reliability
        elif wave_bias in ['BUY_PENDING', 'SELL_PENDING']:
            adjusted_score *= 0.7
        
        # RSI Divergence adjustment (weighted by reliability)
        rsi_reliability = reliability_scores.get('RSI', 50) / 100
        if divergence['type'] == 'BULLISH':
            adjusted_score += divergence['strength'] * 0.15 * rsi_reliability
        elif divergence['type'] == 'BEARISH':
            adjusted_score -= divergence['strength'] * 0.15 * rsi_reliability
        
        # Fibonacci adjustment (weighted by reliability)
        fib_reliability = reliability_scores.get('Fibonacci', 50) / 100
        current_price = latest['Close']
        
        # Check if price is near Fibonacci level
        for level_name, level_value in fib_analysis['levels'].items():
            if abs(current_price - level_value) / current_price < 0.01:  # Within 1%
                if level_value < current_price and fib_analysis['trend'] == 'UPTREND':
                    adjusted_score += 1.0 * fib_reliability  # Near support
                elif level_value > current_price and fib_analysis['trend'] == 'DOWNTREND':
                    adjusted_score -= 1.0 * fib_reliability  # Near resistance
        
        # Support/Resistance adjustment (weighted by reliability)
        sr_reliability = reliability_scores.get('Support/Resistance', 50) / 100
        if abs(current_price - sr_analysis['support']) / current_price < 0.015:
            adjusted_score += 1.2 * sr_reliability  # At strong support
        elif abs(current_price - sr_analysis['resistance']) / current_price < 0.015:
            adjusted_score -= 1.2 * sr_reliability  # At strong resistance
        
        # Moving Average adjustment (weighted by reliability)
        ma_reliability = reliability_scores.get('Moving Averages', 50) / 100
        if latest['SMA_20'] > latest['SMA_50'] > latest['SMA_200']:
            adjusted_score += 0.8 * ma_reliability
        elif latest['SMA_20'] < latest['SMA_50'] < latest['SMA_200']:
            adjusted_score -= 0.8 * ma_reliability
        
        # Ratio analysis adjustment
        if ratio_analysis['relative_strength'] > 1.2:
            adjusted_score += 0.5
        elif ratio_analysis['relative_strength'] < 0.8:
            adjusted_score -= 0.5
        
        # CRITICAL: Give extra weight if most reliable pattern confirms signal
        if most_reliable_pattern != 'INSUFFICIENT_DATA':
            highest_reliability = reliability_scores[most_reliable_pattern]
            
            if highest_reliability > 70:
                # Check if most reliable pattern confirms the signal
                if most_reliable_pattern == 'Elliott Wave' and wave_bias in ['BUY', 'SELL']:
                    adjusted_score *= 1.3  # 30% boost
                elif most_reliable_pattern == 'RSI' and divergence['type'] != 'NONE':
                    adjusted_score *= 1.25
                elif most_reliable_pattern == 'Support/Resistance':
                    if abs(current_price - sr_analysis['support']) / current_price < 0.015 and adjusted_score > 0:
                        adjusted_score *= 1.3
                    elif abs(current_price - sr_analysis['resistance']) / current_price < 0.015 and adjusted_score < 0:
                        adjusted_score *= 1.3
        
        # Determine action and confidence
        if adjusted_score > 2.5:
            action = "BUY"
            confidence = min(adjusted_score / 6 * 100, 95)
        elif adjusted_score < -2.5:
            action = "SELL"
            confidence = min(abs(adjusted_score) / 6 * 100, 95)
        else:
            action = "HOLD"
            confidence = 50 - abs(adjusted_score) * 8
        
        # CRITICAL: Override if most reliable pattern strongly contradicts
        if most_reliable_pattern != 'INSUFFICIENT_DATA':
            highest_reliability = reliability_scores[most_reliable_pattern]
            
            if highest_reliability > 75:
                if most_reliable_pattern == 'Elliott Wave' and elliott_wave['confidence'] > 70:
                    if action == "BUY" and wave_bias == "SELL":
                        action = "HOLD"
                        confidence *= 0.4
                    elif action == "SELL" and wave_bias == "BUY":
                        action = "HOLD"
                        confidence *= 0.4
        
        # Calculate risk management levels using most reliable pattern
        if action == "BUY":
            entry_price = close
            
            # Prioritize most reliable pattern for stop loss
            if most_reliable_pattern == 'Fibonacci' and fib_analysis['nearest_support']:
                stop_loss = min(fib_analysis['nearest_support'][1], close - (2 * atr))
            elif most_reliable_pattern == 'Support/Resistance':
                stop_loss = max(sr_analysis['support'] * 0.99, close - (2 * atr))
            else:
                stop_loss = max(sr_analysis['support'] * 0.99, close - (2 * atr))
            
            # Target using most reliable pattern
            if most_reliable_pattern == 'Fibonacci' and '161.8%' in fib_analysis['extensions']:
                target_price = min(fib_analysis['extensions']['161.8%'], close + (4 * atr))
            elif most_reliable_pattern == 'Support/Resistance':
                target_price = min(sr_analysis['resistance'] * 1.01, close + (3 * atr))
            else:
                target_price = min(sr_analysis['resistance'] * 1.01, close + (3 * atr))
        
        elif action == "SELL":
            entry_price = close
            
            if most_reliable_pattern == 'Fibonacci' and fib_analysis['nearest_resistance']:
                stop_loss = max(fib_analysis['nearest_resistance'][1], close + (2 * atr))
            elif most_reliable_pattern == 'Support/Resistance':
                stop_loss = min(sr_analysis['resistance'] * 1.01, close + (2 * atr))
            else:
                stop_loss = min(sr_analysis['resistance'] * 1.01, close + (2 * atr))
            
            if most_reliable_pattern == 'Fibonacci' and '161.8%' in fib_analysis['extensions']:
                target_price = max(fib_analysis['extensions']['161.8%'], close - (4 * atr))
            elif most_reliable_pattern == 'Support/Resistance':
                target_price = max(sr_analysis['support'] * 0.99, close - (3 * atr))
            else:
                target_price = max(sr_analysis['support'] * 0.99, close - (3 * atr))
        
        else:
            entry_price = close
            stop_loss = close - (1.5 * atr)
            target_price = close + (1.5 * atr)
        
        # Calculate risk-reward ratio
        if action in ["BUY", "SELL"]:
            risk = abs(entry_price - stop_loss)
            reward = abs(target_price - entry_price)
            risk_reward = reward / risk if risk > 0 else 0
        else:
            risk_reward = 1.0
        
        # Generate comprehensive reasoning
        reasoning = self._generate_reasoning(df, action, signals, 
                                             strategy_name, trading_style)
        
        # Generate detailed 200-word summary
        detailed_summary = self._generate_detailed_summary(
            df, action, adjusted_score, sentiment_result, 
            sr_analysis, zscore_analysis, timeframe_signals,
            fib_analysis, divergence, elliott_wave, ratio_analysis,
            pattern_reliability
        )
        
        # Generate signal confluence explanation
        confluence_explanation = self._generate_confluence_explanation(
            timeframe_signals, action, trading_style, elliott_wave, 
            divergence, fib_analysis, pattern_reliability
        )
        
        return TradingSignal(
            action=action,
            confidence=confidence,
            entry_price=entry_price,
            target_price=target_price,
            stop_loss=stop_loss,
            timeframe="Combined",
            strategy=strategy_name.replace('_', ' ').title(),
            reasoning=reasoning,
            risk_reward=risk_reward,
            sentiment_score=sentiment_result['score'],
            sentiment_summary=sentiment_result['summary'],
            strong_support=sr_analysis['support'],
            strong_resistance=sr_analysis['resistance'],
            support_strength=sr_analysis['support_strength'],
            resistance_strength=sr_analysis['resistance_strength'],
            zscore=zscore,
            zscore_interpretation=zscore_analysis['interpretation'],
            timeframe_signals=timeframe_signals,
            detailed_summary=detailed_summary,
            signal_confluence=confluence_explanation
        )
    
    def _generate_detailed_summary(self, df: pd.DataFrame, action: str, 
                                  score: float, sentiment: Dict, 
                                  sr_analysis: Dict, zscore_analysis: Dict,
                                  timeframe_signals: Dict, fib_analysis: Dict = None,
                                  divergence: Dict = None, elliott_wave: Dict = None,
                                  ratio_analysis: Dict = None,
                                  pattern_reliability: Dict = None) -> str:
        """Generate detailed 200-word summary with comprehensive analysis"""
        
        latest = df.iloc[-1]
        prev_week = df.iloc[-5] if len(df) > 5 else df.iloc[0]
        prev_month = df.iloc[-20] if len(df) > 20 else df.iloc[0]
        
        price_change_week = ((latest['Close'] - prev_week['Close']) / prev_week['Close']) * 100
        price_change_month = ((latest['Close'] - prev_month['Close']) / prev_month['Close']) * 100
        
        summary = f"**ðŸ“Š COMPREHENSIVE 200-WORD MARKET ANALYSIS**\n\n"
        
        # Pattern Reliability Analysis (NEW - CRITICAL)
        if pattern_reliability and pattern_reliability['most_reliable'] != 'INSUFFICIENT_DATA':
            most_reliable = pattern_reliability['most_reliable']
            reliability_score = pattern_reliability['reliability_scores'][most_reliable]
            
            summary += f"**ðŸŽ¯ PATTERN RELIABILITY (CRITICAL):**\n"
            summary += f"The market is currently following **{most_reliable}** with {reliability_score:.1f}% historical accuracy. "
            summary += f"This pattern has been the MOST RELIABLE indicator for this instrument. "
            
            if reliability_score > 70:
                summary += f"High reliability (>70%) means this pattern should be PRIMARY decision factor. "
            elif reliability_score > 55:
                summary += f"Moderate reliability means use this with confirming signals. "
            else:
                summary += f"Low reliability means this pattern is currently unreliable - avoid it. "
            
            summary += f"\n\n**Pattern Performance Rankings:**\n"
            sorted_patterns = sorted(pattern_reliability['reliability_scores'].items(), 
                                   key=lambda x: x[1], reverse=True)
            for i, (pattern, score) in enumerate(sorted_patterns[:3], 1):
                emoji = "ðŸ¥‡" if i == 1 else ("ðŸ¥ˆ" if i == 2 else "ðŸ¥‰")
                summary += f"{emoji} {pattern}: {score:.1f}% | "
            summary += "\n\n"
        
        # Historical Performance
        summary += f"**ðŸ“ˆ PAST PERFORMANCE:**\n"
        summary += f"â€¢ Last 5 sessions: â‚¹{prev_week['Close']:.2f} â†’ â‚¹{latest['Close']:.2f} ({price_change_week:+.2f}%)\n"
        summary += f"â€¢ Last 20 sessions: â‚¹{prev_month['Close']:.2f} â†’ â‚¹{latest['Close']:.2f} ({price_change_month:+.2f}%)\n"
        
        if price_change_week > 5:
            summary += f"â€¢ Strong bullish momentum observed - buyers in control.\n"
        elif price_change_week < -5:
            summary += f"â€¢ Strong bearish pressure - sellers dominating.\n"
        else:
            summary += f"â€¢ Consolidation phase - market indecision evident.\n"
        
        # Relative Strength (Market Comparison)
        if ratio_analysis:
            summary += f"â€¢ Relative to benchmark: {ratio_analysis['interpretation']}\n"
        
        # Elliott Wave Position (Market Psychology)
        summary += f"\n**ðŸŒŠ ELLIOTT WAVE (MARKET PSYCHOLOGY):**\n"
        if elliott_wave:
            summary += f"â€¢ Currently in: **{elliott_wave['wave']}** (Confidence: {elliott_wave['confidence']}%)\n"
            summary += f"â€¢ Interpretation: {elliott_wave['description']}\n"
            summary += f"â€¢ Next Expected: {elliott_wave['next_expected']}\n"
            summary += f"â€¢ This wave position suggests: {elliott_wave.get('action_bias', 'NEUTRAL')} bias\n"
            
            if elliott_wave['confidence'] > 70:
                summary += f"â€¢ **HIGH CONFIDENCE** - Elliott Wave pattern is clear and actionable.\n"
        
        # Current Technical Structure
        summary += f"\n**ðŸ”§ CURRENT TECHNICAL STRUCTURE:**\n"
        summary += f"â€¢ Price: â‚¹{latest['Close']:.2f} | RSI: {latest['RSI']:.1f}"
        
        if latest['RSI'] > 70:
            summary += " (Overbought - potential reversal)\n"
        elif latest['RSI'] < 30:
            summary += " (Oversold - potential bounce)\n"
        else:
            summary += " (Neutral zone)\n"
        
        summary += f"â€¢ ADX: {latest['ADX']:.1f}"
        if latest['ADX'] > 25:
            summary += " (Strong trending market - follow trend)\n"
        elif latest['ADX'] > 20:
            summary += " (Moderate trend developing)\n"
        else:
            summary += " (Ranging/choppy market - avoid trend strategies)\n"
        
        summary += f"â€¢ MACD: {latest['MACD']:.3f} | Signal: {latest['MACD_Signal']:.3f}"
        if latest['MACD'] > latest['MACD_Signal']:
            summary += " (Bullish momentum)\n"
        else:
            summary += " (Bearish momentum)\n"
        
        # RSI Divergence (Early Warning)
        if divergence and divergence['type'] != 'NONE':
            summary += f"\n**âš ï¸ RSI DIVERGENCE DETECTED:**\n"
            summary += f"â€¢ Type: **{divergence['type']}** (Strength: {divergence['strength']:.1f})\n"
            summary += f"â€¢ Meaning: {divergence['description']}\n"
            summary += f"â€¢ Divergence often precedes price reversals - this is an EARLY WARNING signal.\n"
        
        # Fibonacci Levels (Natural Support/Resistance)
        if fib_analysis:
            summary += f"\n**ðŸ“ FIBONACCI ANALYSIS ({fib_analysis['trend']}):**\n"
            if fib_analysis['nearest_support']:
                support_dist = ((latest['Close'] - fib_analysis['nearest_support'][1]) / latest['Close']) * 100
                summary += f"â€¢ Nearest Support: â‚¹{fib_analysis['nearest_support'][1]:.2f} ({fib_analysis['nearest_support'][0]}) - {support_dist:.2f}% below\n"
            
            if fib_analysis['nearest_resistance']:
                resist_dist = ((fib_analysis['nearest_resistance'][1] - latest['Close']) / latest['Close']) * 100
                summary += f"â€¢ Nearest Resistance: â‚¹{fib_analysis['nearest_resistance'][1]:.2f} ({fib_analysis['nearest_resistance'][0]}) - {resist_dist:.2f}% above\n"
            
            summary += f"â€¢ Fibonacci levels are natural reversal zones based on golden ratio (1.618).\n"
        
        # Support & Resistance (Key Battle Zones)
        summary += f"\n**ðŸŽšï¸ KEY PRICE LEVELS:**\n"
        summary += f"â€¢ Strong Support: â‚¹{sr_analysis['support']:.2f} ({sr_analysis['support_distance']:.2f}% below)\n"
        summary += f"  Reason: {sr_analysis['support_strength'][:80]}...\n"
        summary += f"â€¢ Strong Resistance: â‚¹{sr_analysis['resistance']:.2f} ({sr_analysis['resistance_distance']:.2f}% above)\n"
        summary += f"  Reason: {sr_analysis['resistance_strength'][:80]}...\n"
        
        # Z-Score (Statistical Edge)
        summary += f"\n**ðŸ“Š Z-SCORE (MEAN REVERSION):**\n"
        summary += f"â€¢ Current Z-Score: **{zscore_analysis['current_zscore']:.2f}**\n"
        
        if abs(zscore_analysis['current_zscore']) > 2:
            summary += f"â€¢ **EXTREME DEVIATION** - Price is {abs(zscore_analysis['current_zscore']):.1f} standard deviations from mean.\n"
            summary += f"â€¢ {zscore_analysis['historical_impact']}\n"
            summary += f"â€¢ Statistical probability favors mean reversion.\n"
        elif abs(zscore_analysis['current_zscore']) > 1:
            summary += f"â€¢ Moderate deviation from mean - watch for reversal signals.\n"
        else:
            summary += f"â€¢ Price near statistical equilibrium - no extreme condition.\n"
        
        # News Sentiment (External Factors)
        summary += f"\n**ðŸ“° NEWS SENTIMENT:**\n"
        summary += f"â€¢ Sentiment: {sentiment['summary']}\n"
        summary += f"â€¢ Score: {sentiment['score']:.3f} (Range: -1 to +1)\n"
        
        if abs(sentiment['score']) > 0.25:
            summary += f"â€¢ Strong sentiment can act as catalyst - consider this in timing entry.\n"
        
        # Final Recommendation with Logic
        summary += f"\n**ðŸŽ¯ FINAL RECOMMENDATION: {action}**\n"
        summary += f"â€¢ Signal Strength Score: {score:.2f}/10\n"
        summary += f"â€¢ Confidence Level: {latest.get('confidence', 'N/A')}\n"
        
        if action == "BUY":
            summary += f"â€¢ **BUY LOGIC:** Multiple bullish confirmations align:\n"
            if pattern_reliability:
                most_reliable = pattern_reliability['most_reliable']
                summary += f"  â†’ Most reliable pattern ({most_reliable}) supports bullish view\n"
            if elliott_wave and 'BUY' in str(elliott_wave.get('action_bias', '')):
                summary += f"  â†’ Elliott Wave in bullish phase\n"
            if divergence and divergence['type'] == 'BULLISH':
                summary += f"  â†’ Bullish RSI divergence detected\n"
            if zscore_analysis['current_zscore'] < -1.5:
                summary += f"  â†’ Oversold conditions (Z-Score)\n"
            
            summary += f"â€¢ Entry: â‚¹{latest['Close']:.2f} | Target: â‚¹{sr_analysis['resistance']:.2f} | Stop: â‚¹{sr_analysis['support']:.2f}\n"
            summary += f"â€¢ Risk/Reward favorable with clear levels defined by most reliable patterns.\n"
        
        elif action == "SELL":
            summary += f"â€¢ **SELL LOGIC:** Multiple bearish confirmations align:\n"
            if pattern_reliability:
                most_reliable = pattern_reliability['most_reliable']
                summary += f"  â†’ Most reliable pattern ({most_reliable}) supports bearish view\n"
            if elliott_wave and 'SELL' in str(elliott_wave.get('action_bias', '')):
                summary += f"  â†’ Elliott Wave in bearish phase\n"
            if divergence and divergence['type'] == 'BEARISH':
                summary += f"  â†’ Bearish RSI divergence detected\n"
            if zscore_analysis['current_zscore'] > 1.5:
                summary += f"  â†’ Overbought conditions (Z-Score)\n"
            
            summary += f"â€¢ Entry: â‚¹{latest['Close']:.2f} | Target: â‚¹{sr_analysis['support']:.2f} | Stop: â‚¹{sr_analysis['resistance']:.2f}\n"
            summary += f"â€¢ Risk/Reward favorable for short positions.\n"
        
        else:
            summary += f"â€¢ **HOLD LOGIC:** Conflicting signals or weak setup:\n"
            summary += f"  â†’ No clear confluence across multiple indicators\n"
            summary += f"  â†’ Most reliable patterns show indecision\n"
            summary += f"  â†’ Risk/reward not favorable in current context\n"
            summary += f"â€¢ **Professional traders wait for high-probability setups.**\n"
            summary += f"â€¢ Patience is a position - not every moment requires action.\n"
        
        # Future Forecast
        summary += f"\n**ðŸ”® FORWARD OUTLOOK:**\n"
        summary += f"{zscore_analysis['future_outlook'][:150]}... "
        
        if pattern_reliability:
            most_reliable = pattern_reliability['most_reliable']
            summary += f"Given {most_reliable} is most reliable ({pattern_reliability['reliability_scores'][most_reliable]:.1f}% accuracy), "
            summary += f"this pattern should be PRIMARY guide for next move. "
        
        summary += f"\n\n**âš™ï¸ DECISION METHODOLOGY:**\n"
        summary += f"This recommendation synthesizes 10+ technical factors, weighted by historical reliability. "
        summary += f"Each indicator is tested for accuracy on recent data. Most reliable patterns receive highest weight. "
        summary += f"Elliott Wave captures psychology, Fibonacci marks natural levels, divergence shows momentum shifts, "
        summary += f"and Z-Score provides statistical edge. Only when multiple HIGH-RELIABILITY factors align "
        summary += f"do we generate BUY/SELL signals. This multi-layered approach significantly improves win probability."
        
        return summary
        """Generate detailed 100-word summary with values"""
        
        latest = df.iloc[-1]
        prev_week = df.iloc[-5] if len(df) > 5 else df.iloc[0]
        
        price_change = ((latest['Close'] - prev_week['Close']) / prev_week['Close']) * 100
        
        summary = f"**Comprehensive Market Summary:**\n\n"
        
        # Past Structure
        summary += f"**Past Performance:** Price moved from â‚¹{prev_week['Close']:.2f} to â‚¹{latest['Close']:.2f} "
        summary += f"({price_change:+.2f}%). "
        
        if ratio_analysis:
            summary += f"{ratio_analysis['interpretation']} "
        
        # Elliott Wave Position (CRITICAL)
        if elliott_wave:
            summary += f"\n\n**Elliott Wave:** Currently in {elliott_wave['wave']} "
            summary += f"({elliott_wave['confidence']}% confidence). {elliott_wave['description']} "
            summary += f"Next expected: {elliott_wave['next_expected']}. "
        
        # Current Technical Structure
        summary += f"\n\n**Technical Indicators:** RSI={latest['RSI']:.1f} "
        if latest['RSI'] > 70:
            summary += "(overbought), "
        elif latest['RSI'] < 30:
            summary += "(oversold), "
        else:
            summary += "(neutral), "
        
        summary += f"ADX={latest['ADX']:.1f} "
        if latest['ADX'] > 25:
            summary += "(strong trend), "
        else:
            summary += "(weak trend), "
        
        summary += f"MACD={latest['MACD']:.3f}. "
        
        # RSI Divergence
        if divergence and divergence['type'] != 'NONE':
            summary += f"\n\n**RSI Divergence Detected:** {divergence['description']} "
        
        # Fibonacci Levels
        if fib_analysis:
            summary += f"\n\n**Fibonacci Analysis ({fib_analysis['trend']}):** "
            if fib_analysis['nearest_support']:
                summary += f"Nearest support at â‚¹{fib_analysis['nearest_support'][1]:.2f} ({fib_analysis['nearest_support'][0]}). "
            if fib_analysis['nearest_resistance']:
                summary += f"Nearest resistance at â‚¹{fib_analysis['nearest_resistance'][1]:.2f} ({fib_analysis['nearest_resistance'][0]}). "
        
        # Z-Score
        summary += f"\n\n**Mean Reversion:** Z-Score={zscore_analysis['current_zscore']:.2f}. "
        if abs(zscore_analysis['current_zscore']) > 2:
            summary += "Extreme deviation detected - high probability of mean reversion. "
        
        # Sentiment
        summary += f"\n\n**News Sentiment:** {sentiment['summary']} (score: {sentiment['score']:.2f}). "
        
        # Final Recommendation
        summary += f"\n\n**Final Signal: {action}** (Score: {score:.1f}). "
        
        if action == "BUY":
            summary += f"Multiple confirmations align for upward move. "
            if elliott_wave and 'BUY' in elliott_wave.get('action_bias', ''):
                summary += f"Elliott Wave confirms bullish setup. "
            summary += f"Target: â‚¹{sr_analysis['resistance']:.2f}, Stop: â‚¹{sr_analysis['support']:.2f}. "
        elif action == "SELL":
            summary += f"Multiple confirmations align for downward move. "
            if elliott_wave and 'SELL' in elliott_wave.get('action_bias', ''):
                summary += f"Elliott Wave confirms bearish setup. "
            summary += f"Target: â‚¹{sr_analysis['support']:.2f}, Stop: â‚¹{sr_analysis['resistance']:.2f}. "
        else:
            summary += f"Conflicting signals or weak setup. Patience advised until clearer picture emerges. "
        
        summary += f"\n\n**Logic:** This recommendation is based on confluence of technical indicators, Elliott Wave positioning, Fibonacci levels, RSI divergence, sentiment analysis, and relative strength. All factors must align for high-probability trades."
        
        return summary
    
    def _generate_confluence_explanation(self, timeframe_signals: Dict, 
                                        final_action: str, trading_style: str,
                                        elliott_wave: Dict = None,
                                        divergence: Dict = None,
                                        fib_analysis: Dict = None,
                                        pattern_reliability: Dict = None) -> str:
        """Explain how different factors and pattern reliability contributed to final decision"""
        
        explanation = f"**ðŸŽ¯ MULTI-FACTOR CONFLUENCE ANALYSIS FOR {trading_style}**\n\n"
        
        # Pattern Reliability (MOST IMPORTANT SECTION)
        if pattern_reliability and pattern_reliability['most_reliable'] != 'INSUFFICIENT_DATA':
            explanation += f"**ðŸ“Š PATTERN RELIABILITY ANALYSIS (FOUNDATION OF DECISION):**\n\n"
            explanation += f"We tested which patterns this market follows most consistently:\n\n"
            
            for rec in pattern_reliability['recommendations']:
                explanation += f"{rec}\n"
            
            most_reliable = pattern_reliability['most_reliable']
            reliability_score = pattern_reliability['reliability_scores'][most_reliable]
            
            explanation += f"\n**ðŸŽ¯ PRIMARY DECISION DRIVER: {most_reliable} ({reliability_score:.1f}% Accurate)**\n"
            explanation += f"This pattern has been correct {reliability_score:.1f}% of the time historically. "
            
            if reliability_score > 75:
                explanation += f"This is EXCEPTIONALLY HIGH reliability - we give this pattern 3X weight in decision. "
            elif reliability_score > 65:
                explanation += f"This is HIGH reliability - we give this pattern 2X weight. "
            elif reliability_score > 55:
                explanation += f"This is MODERATE reliability - we use it with confirming signals. "
            else:
                explanation += f"This is LOW reliability - we minimize its influence. "
            
            explanation += f"\n\n**Logic:** Why follow the most reliable pattern? Because past performance "
            explanation += f"indicates future probability. If {most_reliable} has been 75% accurate, "
            explanation += f"following it gives you a statistical edge. Markets are not random - they follow patterns. "
            explanation += f"Our job is to identify WHICH pattern is working NOW.\n\n"
        
        # Elliott Wave Section
        if elliott_wave:
            reliability = pattern_reliability['reliability_scores'].get('Elliott Wave', 50) if pattern_reliability else 50
            explanation += f"**ðŸŒŠ ELLIOTT WAVE ANALYSIS ({reliability:.1f}% Reliable):**\n"
            explanation += f"â€¢ Current Wave: {elliott_wave['wave']}\n"
            explanation += f"â€¢ Confidence: {elliott_wave['confidence']}%\n"
            explanation += f"â€¢ Pattern: {elliott_wave['description']}\n"
            explanation += f"â€¢ Expected Next: {elliott_wave['next_expected']}\n"
            explanation += f"â€¢ Wave Bias: {elliott_wave.get('action_bias', 'N/A')}\n"
            
            if reliability > 70:
                explanation += f"â€¢ **HIGH RELIABILITY** - Elliott Wave is working well for this instrument\n"
            
            explanation += f"\n**Why Elliott Wave?** It captures crowd psychology. Wave 3 is always strongest (greed peak), "
            explanation += f"Wave 5 often fails (exhaustion), Wave 4 provides entry (correction). "
            explanation += f"When pattern has {reliability:.1f}% accuracy, it's highly actionable.\n\n"
        
        # RSI Divergence
        if divergence and divergence['type'] != 'NONE':
            reliability = pattern_reliability['reliability_scores'].get('RSI', 50) if pattern_reliability else 50
            explanation += f"**ðŸ“Š RSI DIVERGENCE ({reliability:.1f}% Reliable):**\n"
            explanation += f"â€¢ Type: {divergence['type']}\n"
            explanation += f"â€¢ Strength: {divergence['strength']:.1f}\n"
            explanation += f"â€¢ Explanation: {divergence['description']}\n"
            
            if reliability > 65:
                explanation += f"â€¢ **STRONG SIGNAL** - RSI divergence reliable for this market\n"
            
            explanation += f"\n**Why Divergence?** It's a leading indicator - shows momentum shift BEFORE price reverses. "
            explanation += f"When price makes new high but RSI doesn't, buying pressure is weakening.\n\n"
        
        # Fibonacci
        if fib_analysis:
            reliability = pattern_reliability['reliability_scores'].get('Fibonacci', 50) if pattern_reliability else 50
            explanation += f"**ðŸ“ FIBONACCI LEVELS ({reliability:.1f}% Reliable):**\n"
            explanation += f"â€¢ Trend: {fib_analysis['trend']}\n"
            
            if fib_analysis['nearest_support']:
                explanation += f"â€¢ Support: â‚¹{fib_analysis['nearest_support'][1]:.2f} ({fib_analysis['nearest_support'][0]})\n"
            if fib_analysis['nearest_resistance']:
                explanation += f"â€¢ Resistance: â‚¹{fib_analysis['nearest_resistance'][1]:.2f} ({fib_analysis['nearest_resistance'][0]})\n"
            
            if reliability > 65:
                explanation += f"â€¢ **HIGHLY EFFECTIVE** - Fib levels acting as strong S/R\n"
            
            explanation += f"\n**Why Fibonacci?** Based on golden ratio (1.618) found in nature. "
            explanation += f"Traders worldwide watch 38.2%, 50%, 61.8% levels - becomes self-fulfilling.\n\n"
        
        # Multi-Timeframe
        if timeframe_signals:
            buy_count = sum(1 for data in timeframe_signals.values() if data['signal'] == 'BUY')
            sell_count = sum(1 for data in timeframe_signals.values() if data['signal'] == 'SELL')
            hold_count = sum(1 for data in timeframe_signals.values() if data['signal'] == 'HOLD')
            
            explanation += f"**â±ï¸ MULTI-TIMEFRAME CONFIRMATION:**\n"
            for tf, data in timeframe_signals.items():
                emoji = "ðŸŸ¢" if data['signal'] == "BUY" else ("ðŸ”´" if data['signal'] == "SELL" else "ðŸŸ¡")
                explanation += f"{emoji} {tf}: {data['signal']} | {data['market_structure'].replace('_', ' ').title()}\n"
            
            explanation += f"\nâ€¢ BUY signals: {buy_count}/{len(timeframe_signals)}\n"
            explanation += f"â€¢ SELL signals: {sell_count}/{len(timeframe_signals)}\n"
            explanation += f"â€¢ HOLD signals: {hold_count}/{len(timeframe_signals)}\n\n"
        
        # Final Decision Logic with Pattern Reliability
        explanation += f"**ðŸŽ¯ WHY {final_action} WILL WORK - THE COMPLETE LOGIC:**\n\n"
        
        if final_action == "BUY":
            explanation += "âœ… **BULLISH CONFLUENCE DETECTED - Multiple High-Probability Factors Align:**\n\n"
            
            if pattern_reliability:
                most_reliable = pattern_reliability['most_reliable']
                score = pattern_reliability['reliability_scores'][most_reliable]
                
                if 'Elliott' in most_reliable or 'Wave' in most_reliable:
                    if elliott_wave and 'BUY' in str(elliott_wave.get('action_bias', '')):
                        explanation += f"1ï¸âƒ£ **PRIMARY SIGNAL**: {most_reliable} ({score:.1f}% accurate) indicates BUY\n"
                        explanation += f"   â†’ Wave position: {elliott_wave['wave']}\n"
                        explanation += f"   â†’ This wave typically shows upward movement\n\n"
                
                elif 'Fibonacci' in most_reliable:
                    if fib_analysis and fib_analysis['nearest_support']:
                        dist = abs((latest['Close'] - fib_analysis['nearest_support'][1]) / latest['Close'])
                        if dist < 0.02:
                            explanation += f"1ï¸âƒ£ **PRIMARY SIGNAL**: {most_reliable} ({score:.1f}% accurate) - Near Fib Support\n"
                            explanation += f"   â†’ Price at {fib_analysis['nearest_support'][0]} level\n"
                            explanation += f"   â†’ This level bounced {score:.0f}% of time historically\n\n"
                
                elif 'Support' in most_reliable or 'Resistance' in most_reliable:
                    explanation += f"1ï¸âƒ£ **PRIMARY SIGNAL**: {most_reliable} ({score:.1f}% accurate) confirms BUY\n"
                    explanation += f"   â†’ Near strong support level\n"
                    explanation += f"   â†’ Historical bounce rate: {score:.0f}%\n\n"
            
            if divergence and divergence['type'] == 'BULLISH':
                explanation += f"2ï¸âƒ£ **CONFIRMING SIGNAL**: Bullish RSI Divergence\n"
                explanation += f"   â†’ {divergence['description']}\n"
                explanation += f"   â†’ Leading indicator of reversal\n\n"
            
            if timeframe_signals and buy_count >= 2:
                explanation += f"3ï¸âƒ£ **MULTI-TIMEFRAME ALIGNMENT**: {buy_count}/{len(timeframe_signals)} timeframes bullish\n"
                explanation += f"   â†’ Higher timeframes confirm trend direction\n"
                explanation += f"   â†’ Lower timeframes identify precise entry\n\n"
            
            explanation += f"**SUCCESS PROBABILITY LOGIC:**\n"
            explanation += f"â€¢ When most reliable pattern ({pattern_reliability['most_reliable']} - {pattern_reliability['reliability_scores'][pattern_reliability['most_reliable']]:.1f}% accurate) aligns with confirming signals\n"
            explanation += f"â€¢ AND multiple timeframes agree\n"
            explanation += f"â€¢ AND divergence shows early momentum shift\n"
            explanation += f"â€¢ THEN probability of success increases multiplicatively\n"
            explanation += f"â€¢ Single indicator: ~{pattern_reliability['reliability_scores'][pattern_reliability['most_reliable']]:.0f}% accuracy\n"
            explanation += f"â€¢ Multiple confirmation: ~{min(pattern_reliability['reliability_scores'][pattern_reliability['most_reliable']] * 1.3, 90):.0f}% accuracy\n"
            explanation += f"\nðŸŽ¯ **Entry Strategy**: Buy near current level with stop below most reliable support level.\n"
        
        elif final_action == "SELL":
            explanation += "âœ… **BEARISH CONFLUENCE DETECTED - Multiple High-Probability Factors Align:**\n\n"
            
            if pattern_reliability:
                most_reliable = pattern_reliability['most_reliable']
                score = pattern_reliability['reliability_scores'][most_reliable]
                
                explanation += f"1ï¸âƒ£ **PRIMARY SIGNAL**: {most_reliable} ({score:.1f}% accurate) indicates SELL\n"
                
                if 'Elliott' in most_reliable and elliott_wave:
                    explanation += f"   â†’ Wave position: {elliott_wave['wave']}\n"
                    explanation += f"   â†’ This wave typically shows downward pressure\n\n"
            
            if divergence and divergence['type'] == 'BEARISH':
                explanation += f"2ï¸âƒ£ **CONFIRMING SIGNAL**: Bearish RSI Divergence\n"
                explanation += f"   â†’ {divergence['description']}\n"
                explanation += f"   â†’ Momentum weakening despite higher prices\n\n"
            
            if timeframe_signals and sell_count >= 2:
                explanation += f"3ï¸âƒ£ **MULTI-TIMEFRAME ALIGNMENT**: {sell_count}/{len(timeframe_signals)} timeframes bearish\n\n"
            
            explanation += f"**SUCCESS PROBABILITY LOGIC:** Same multiplicative effect as BUY, but in bearish direction.\n"
            explanation += f"ðŸŽ¯ **Entry Strategy**: Short near current level with stop above most reliable resistance.\n"
        
        else:
            explanation += "âš ï¸ **HOLD RECOMMENDED - Insufficient Confluence:**\n\n"
            explanation += f"**Why HOLD is the Right Decision:**\n"
            explanation += f"â€¢ Conflicting signals across patterns\n"
            explanation += f"â€¢ Most reliable pattern shows indecision\n"
            explanation += f"â€¢ Multiple timeframes disagree\n"
            explanation += f"â€¢ No clear statistical edge\n\n"
            
            explanation += f"**Professional Trading Rule:** Only trade when you have EDGE.\n"
            explanation += f"Edge = (Win Rate Ã— Avg Win) > (Loss Rate Ã— Avg Loss)\n"
            explanation += f"Current setup doesn't provide sufficient edge.\n"
            explanation += f"Patience preserves capital for high-probability setups.\n"
        
        explanation += f"\n**ðŸ§  PSYCHOLOGICAL NOTE:**\n"
        if final_action in ["BUY", "SELL"]:
            explanation += f"Having multi-layered confirmation helps you stay disciplined. "
            explanation += f"When most reliable pattern + divergence + timeframes align, "
            explanation += f"you can trust the setup and avoid emotional exit. "
            explanation += f"This is how professional traders maintain consistency."
        else:
            explanation += f"Resisting FOMO (Fear of Missing Out) is crucial. "
            explanation += f"Missing marginal setups preserves capital for clear opportunities. "
            explanation += f"Trading without edge leads to slow capital erosion."
        
        return explanation
        """Explain how different timeframes and Elliott Wave contributed to final decision"""
        
        explanation = f"**Multi-Factor Confluence Analysis for {trading_style}:**\n\n"
        
        # Elliott Wave Section (Most Important)
        if elliott_wave:
            explanation += f"**ðŸŒŠ Elliott Wave Analysis (CRITICAL):**\n"
            explanation += f"â€¢ Current Wave: {elliott_wave['wave']}\n"
            explanation += f"â€¢ Confidence: {elliott_wave['confidence']}%\n"
            explanation += f"â€¢ Pattern: {elliott_wave['description']}\n"
            explanation += f"â€¢ Expected Next: {elliott_wave['next_expected']}\n"
            explanation += f"â€¢ Wave Bias: {elliott_wave.get('action_bias', 'N/A')}\n\n"
            
            explanation += f"**Why Elliott Wave Matters:** Elliott Wave theory captures the psychology of market participants. "
            if elliott_wave['confidence'] > 70:
                explanation += f"High confidence ({elliott_wave['confidence']}%) means the pattern is clear and reliable. "
            explanation += f"Currently in {elliott_wave['wave']}, which historically shows specific behavior patterns.\n\n"
        
        # RSI Divergence
        if divergence and divergence['type'] != 'NONE':
            explanation += f"**ðŸ“Š RSI Divergence:**\n"
            explanation += f"â€¢ Type: {divergence['type']}\n"
            explanation += f"â€¢ Strength: {divergence['strength']:.1f}\n"
            explanation += f"â€¢ Explanation: {divergence['description']}\n\n"
        
        # Fibonacci
        if fib_analysis:
            explanation += f"**ðŸ“ Fibonacci Levels:**\n"
            explanation += f"â€¢ Trend: {fib_analysis['trend']}\n"
            if fib_analysis['nearest_support']:
                explanation += f"â€¢ Support: â‚¹{fib_analysis['nearest_support'][1]:.2f} at {fib_analysis['nearest_support'][0]}\n"
            if fib_analysis['nearest_resistance']:
                explanation += f"â€¢ Resistance: â‚¹{fib_analysis['nearest_resistance'][1]:.2f} at {fib_analysis['nearest_resistance'][0]}\n"
            explanation += f"Fibonacci levels mark natural support/resistance where traders take action.\n\n"
        
        # Multi-Timeframe
        if timeframe_signals:
            buy_count = sum(1 for data in timeframe_signals.values() if data['signal'] == 'BUY')
            sell_count = sum(1 for data in timeframe_signals.values() if data['signal'] == 'SELL')
            hold_count = sum(1 for data in timeframe_signals.values() if data['signal'] == 'HOLD')
            
            explanation += f"**â±ï¸ Multi-Timeframe Signals:**\n"
            for tf, data in timeframe_signals.items():
                emoji = "ðŸŸ¢" if data['signal'] == "BUY" else ("ðŸ”´" if data['signal'] == "SELL" else "ðŸŸ¡")
                explanation += f"{emoji} {tf}: {data['signal']} ({data['market_structure'].replace('_', ' ').title()})\n"
            
            explanation += f"\nâ€¢ BUY: {buy_count}/{len(timeframe_signals)}\n"
            explanation += f"â€¢ SELL: {sell_count}/{len(timeframe_signals)}\n"
            explanation += f"â€¢ HOLD: {hold_count}/{len(timeframe_signals)}\n\n"
        
        # Final Decision Logic
        explanation += f"**ðŸŽ¯ Why {final_action} Will Work:**\n\n"
        
        if final_action == "BUY":
            explanation += "âœ… **Bullish Confluence Detected:**\n"
            if elliott_wave and 'BUY' in elliott_wave.get('action_bias', ''):
                explanation += f"â€¢ Elliott Wave in bullish phase ({elliott_wave['wave']})\n"
            if divergence and divergence['type'] == 'BULLISH':
                explanation += f"â€¢ Bullish RSI divergence confirms momentum shift\n"
            if fib_analysis and fib_analysis['nearest_support']:
                explanation += f"â€¢ Price near Fibonacci support - high probability bounce zone\n"
            
            explanation += f"\n**Success Logic:** When Elliott Wave, divergence, and Fibonacci align bullishly, "
            explanation += f"it creates a high-probability setup. The market psychology (Elliott Wave) "
            explanation += f"indicates we're in a buying phase, technical divergence confirms momentum building, "
            explanation += f"and Fibonacci support provides a safety net. This multi-layered confirmation "
            explanation += f"significantly improves success probability."
        
        elif final_action == "SELL":
            explanation += "âœ… **Bearish Confluence Detected:**\n"
            if elliott_wave and 'SELL' in elliott_wave.get('action_bias', ''):
                explanation += f"â€¢ Elliott Wave in bearish phase ({elliott_wave['wave']})\n"
            if divergence and divergence['type'] == 'BEARISH':
                explanation += f"â€¢ Bearish RSI divergence confirms weakening momentum\n"
            if fib_analysis and fib_analysis['nearest_resistance']:
                explanation += f"â€¢ Price near Fibonacci resistance - high probability rejection zone\n"
            
            explanation += f"\n**Success Logic:** Bearish Elliott Wave position indicates distribution phase, "
            explanation += f"divergence shows weakening buying pressure despite higher prices, "
            explanation += f"and Fibonacci resistance acts as selling pressure zone. "
            explanation += f"This combination creates high-probability short setup."
        
        else:
            explanation += "âš ï¸ **Conflicting Signals - HOLD Recommended:**\n"
            explanation += f"â€¢ Different timeframes or indicators show conflicting directions\n"
            explanation += f"â€¢ Elliott Wave may not be in decisive phase\n"
            explanation += f"â€¢ No clear confluence across multiple factors\n"
            explanation += f"\n**Logic:** Trading without confluence reduces win probability. "
            explanation += f"Professional traders wait for alignment across multiple factors. "
            explanation += f"Current setup lacks the multi-layered confirmation needed for high-confidence trade."
        
        return explanation
    
    def _generate_reasoning(self, df: pd.DataFrame, action: str, 
                           signals: List[str], strategy: str, 
                           trading_style: str) -> str:
        """Generate human-readable reasoning"""
        latest = df.iloc[-1]
        market_structure = self.detect_market_structure(df)
        
        reasoning = f"**Market Analysis ({trading_style})**\n\n"
        reasoning += f"â€¢ Market Structure: {market_structure.replace('_', ' ').title()}\n"
        reasoning += f"â€¢ Selected Strategy: {strategy.replace('_', ' ').title()}\n"
        reasoning += f"â€¢ Current Price: â‚¹{latest['Close']:.2f}\n\n"
        
        reasoning += "**Key Indicators:**\n"
        reasoning += f"â€¢ RSI: {latest['RSI']:.1f} "
        if latest['RSI'] < 30:
            reasoning += "(Oversold)\n"
        elif latest['RSI'] > 70:
            reasoning += "(Overbought)\n"
        else:
            reasoning += "(Neutral)\n"
        
        reasoning += f"â€¢ ADX: {latest['ADX']:.1f} "
        if latest['ADX'] > 25:
            reasoning += "(Strong Trend)\n"
        else:
            reasoning += "(Weak Trend)\n"
        
        reasoning += f"â€¢ Volume Ratio: {latest['Volume_Ratio']:.2f}x average\n\n"
        
        reasoning += "**Signal Triggers:**\n"
        for signal in signals[:5]:  # Top 5 signals
            reasoning += f"â€¢ {signal}\n"
        
        reasoning += f"\n**Recommendation: {action}**\n"
        
        # Psychology considerations
        reasoning += "\n**âš ï¸ Trading Psychology Reminder:**\n"
        if action == "BUY":
            reasoning += "â€¢ Don't chase the price - wait for your entry\n"
            reasoning += "â€¢ Set stop-loss BEFORE entering trade\n"
            reasoning += "â€¢ Fear of missing out (FOMO) clouds judgment\n"
        elif action == "SELL":
            reasoning += "â€¢ Don't panic sell - follow your plan\n"
            reasoning += "â€¢ Protect profits with trailing stops\n"
            reasoning += "â€¢ Greed can turn winners into losers\n"
        else:
            reasoning += "â€¢ Patience is a position - not every moment needs action\n"
            reasoning += "â€¢ Overtrading reduces profitability\n"
            reasoning += "â€¢ Wait for high-probability setups\n"
        
        return reasoning

class BacktestEngine:
    """Backtesting Engine with Parameter Optimization for 20% Annual Returns"""
    
    @staticmethod
    def optimize_strategy_parameters(df: pd.DataFrame, strategy_name: str, 
                                     target_annual_return: float = 20.0) -> Dict:
        """Optimize strategy parameters to achieve target returns"""
        
        if len(df) < 100:
            return {
                'optimized': False,
                'best_params': {
                    'entry_threshold': 2.0,
                    'stop_loss_atr': 2.0,
                    'take_profit_atr': 3.0
                },
                'annual_return': 0,
                'message': 'Insufficient data for optimization'
            }
        
        best_annual_return = -999
        best_params = {
            'entry_threshold': 2.0,
            'exit_threshold': -1.0,
            'stop_loss_atr': 2.0,
            'take_profit_atr': 3.0,
            'risk_reward_min': 1.5
        }
        
        # More aggressive parameter grid search for more trades
        entry_thresholds = [1.5, 2.0, 2.5, 3.0]
        stop_loss_atrs = [1.5, 2.0, 2.5, 3.0]
        take_profit_atrs = [2.0, 2.5, 3.0, 3.5, 4.0]
        
        for entry_thresh in entry_thresholds:
            for sl_atr in stop_loss_atrs:
                for tp_atr in take_profit_atrs:
                    # Only test if risk/reward >= 1.2 (relaxed from 1.5)
                    if tp_atr / sl_atr < 1.2:
                        continue
                    
                    try:
                        result = BacktestEngine.run_backtest(
                            df, strategy_name, 
                            params={
                                'entry_threshold': entry_thresh,
                                'stop_loss_atr': sl_atr,
                                'take_profit_atr': tp_atr
                            }
                        )
                        
                        if result.annual_return > best_annual_return:
                            best_annual_return = result.annual_return
                            best_params = {
                                'entry_threshold': entry_thresh,
                                'stop_loss_atr': sl_atr,
                                'take_profit_atr': tp_atr,
                                'risk_reward_min': tp_atr / sl_atr
                            }
                    except Exception as e:
                        continue
        
        # More lenient optimization check
        optimized = best_annual_return >= target_annual_return * 0.5  # 50% of target
        
        return {
            'optimized': optimized,
            'best_params': best_params,
            'annual_return': best_annual_return,
            'message': f"Achieved {best_annual_return:.2f}% annual return" if best_annual_return > 0
                      else f"Best achievable: {best_annual_return:.2f}% (Target: {target_annual_return}%)"
        }
    
    @staticmethod
    def run_backtest(df: pd.DataFrame, strategy_name: str, 
                     initial_capital: float = 100000,
                     params: Dict = None) -> BacktestResult:
        """Run backtest with optimized parameters"""
        
        if len(df) < 100:
            return BacktestResult(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
        
        # Default parameters
        if params is None:
            params = {
                'entry_threshold': 2.5,
                'stop_loss_atr': 2.0,
                'take_profit_atr': 3.0
            }
        
        strategy_engine = StrategyEngine()
        strategy_func = strategy_engine.strategies[strategy_name]
        
        trades = []
        capital = initial_capital
        position = None
        equity_curve = [initial_capital]
        
        for i in range(50, len(df) - 1):
            window_df = df.iloc[:i+1].copy()
            latest = window_df.iloc[-1]
            
            result = strategy_func(window_df)
            score = result['score']
            
            # Elliott Wave and other confirmations
            elliott = ElliottWaveAnalyzer.detect_elliott_wave(window_df, lookback=30)
            wave_bias = elliott.get('action_bias', 'HOLD')
            fib = FibonacciAnalyzer.calculate_fibonacci_levels(window_df)
            divergence = RSIDivergenceAnalyzer.detect_divergence(window_df)
            
            # Entry with optimized threshold
            if position is None:
                if score > params['entry_threshold']:
                    if wave_bias in ['BUY', 'BUY_PENDING'] or elliott['confidence'] < 50:
                        if divergence['type'] in ['BULLISH', 'NONE']:
                            position = {
                                'type': 'LONG',
                                'entry_price': latest['Close'],
                                'entry_idx': i,
                                'stop_loss': latest['Close'] - (params['stop_loss_atr'] * latest['ATR']),
                                'target': latest['Close'] + (params['take_profit_atr'] * latest['ATR']),
                                'wave': elliott['wave']
                            }
                
                elif score < -params['entry_threshold']:
                    if wave_bias in ['SELL', 'SELL_PENDING'] or elliott['confidence'] < 50:
                        if divergence['type'] in ['BEARISH', 'NONE']:
                            position = {
                                'type': 'SHORT',
                                'entry_price': latest['Close'],
                                'entry_idx': i,
                                'stop_loss': latest['Close'] + (params['stop_loss_atr'] * latest['ATR']),
                                'target': latest['Close'] - (params['take_profit_atr'] * latest['ATR']),
                                'wave': elliott['wave']
                            }
            
            # Exit logic
            elif position is not None:
                current_price = latest['Close']
                entry_price = position['entry_price']
                
                exit_trade = False
                exit_reason = None
                
                if position['type'] == 'LONG':
                    if current_price >= position['target']:
                        exit_trade = True
                        exit_reason = 'TARGET'
                    elif current_price <= position['stop_loss']:
                        exit_trade = True
                        exit_reason = 'STOP_LOSS'
                    elif score < -1 or wave_bias == 'SELL':
                        exit_trade = True
                        exit_reason = 'SIGNAL_REVERSAL'
                else:
                    if current_price <= position['target']:
                        exit_trade = True
                        exit_reason = 'TARGET'
                    elif current_price >= position['stop_loss']:
                        exit_trade = True
                        exit_reason = 'STOP_LOSS'
                    elif score > 1 or wave_bias == 'BUY':
                        exit_trade = True
                        exit_reason = 'SIGNAL_REVERSAL'
                
                if exit_trade:
                    if position['type'] == 'LONG':
                        pnl = current_price - entry_price
                    else:
                        pnl = entry_price - current_price
                    
                    pnl_pct = (pnl / entry_price) * 100
                    capital += (capital * pnl_pct / 100)
                    
                    trades.append({
                        'entry': entry_price,
                        'exit': current_price,
                        'pnl': pnl,
                        'pnl_pct': pnl_pct,
                        'type': position['type'],
                        'reason': exit_reason,
                        'wave': position.get('wave', 'N/A')
                    })
                    
                    position = None
            
            equity_curve.append(capital)
        
        # Calculate statistics
        if not trades:
            return BacktestResult(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
        
        total_trades = len(trades)
        winning_trades = len([t for t in trades if t['pnl'] > 0])
        losing_trades = len([t for t in trades if t['pnl'] <= 0])
        win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0
        
        profits = [t['pnl_pct'] for t in trades if t['pnl'] > 0]
        losses = [abs(t['pnl_pct']) for t in trades if t['pnl'] <= 0]
        
        avg_profit = np.mean(profits) if profits else 0
        avg_loss = np.mean(losses) if losses else 0
        
        total_profit = sum(profits)
        total_loss = sum(losses)
        profit_factor = (total_profit / total_loss) if total_loss > 0 else 0
        
        # Max drawdown
        equity_array = np.array(equity_curve)
        running_max = np.maximum.accumulate(equity_array)
        drawdown = (equity_array - running_max) / running_max * 100
        max_drawdown = abs(np.min(drawdown))
        
        total_return = ((capital - initial_capital) / initial_capital) * 100
        
        # Annualized return
        days = len(df)
        years = days / 252
        annual_return = (total_return / years) if years > 0 else 0
        
        # Sharpe ratio
        returns = pd.Series([t['pnl_pct'] for t in trades])
        sharpe_ratio = (returns.mean() / returns.std() * np.sqrt(252)) if len(returns) > 1 else 0
        
        return BacktestResult(
            total_trades=total_trades,
            winning_trades=winning_trades,
            losing_trades=losing_trades,
            win_rate=win_rate,
            avg_profit=avg_profit,
            avg_loss=avg_loss,
            profit_factor=profit_factor,
            max_drawdown=max_drawdown,
            total_return=total_return,
            annual_return=annual_return,
            sharpe_ratio=sharpe_ratio
        )
        """Run backtest on historical data with Elliott Wave confirmation"""
        
        if len(df) < 100:
            return BacktestResult(0, 0, 0, 0, 0, 0, 0, 0, 0)
        
        strategy_engine = StrategyEngine()
        strategy_func = strategy_engine.strategies[strategy_name]
        
        trades = []
        capital = initial_capital
        position = None
        equity_curve = [initial_capital]
        
        for i in range(50, len(df) - 1):
            window_df = df.iloc[:i+1].copy()
            latest = window_df.iloc[-1]
            
            # Generate signal
            result = strategy_func(window_df)
            score = result['score']
            
            # Elliott Wave analysis for confirmation
            elliott = ElliottWaveAnalyzer.detect_elliott_wave(window_df, lookback=30)
            wave_bias = elliott.get('action_bias', 'HOLD')
            
            # Fibonacci analysis
            fib = FibonacciAnalyzer.calculate_fibonacci_levels(window_df)
            
            # RSI Divergence
            divergence = RSIDivergenceAnalyzer.detect_divergence(window_df)
            
            # Entry logic with Elliott Wave confirmation
            if position is None:
                # BUY signal with confirmations
                if score > 2:
                    # Require Elliott Wave confirmation
                    if wave_bias in ['BUY', 'BUY_PENDING'] or elliott['confidence'] < 50:
                        # Additional confirmation from divergence
                        if divergence['type'] in ['BULLISH', 'NONE']:
                            position = {
                                'type': 'LONG',
                                'entry_price': latest['Close'],
                                'entry_idx': i,
                                'stop_loss': latest['Close'] - (2 * latest['ATR']),
                                'target': latest['Close'] + (3 * latest['ATR']),
                                'wave': elliott['wave']
                            }
                
                # SELL signal with confirmations
                elif score < -2:
                    if wave_bias in ['SELL', 'SELL_PENDING'] or elliott['confidence'] < 50:
                        if divergence['type'] in ['BEARISH', 'NONE']:
                            position = {
                                'type': 'SHORT',
                                'entry_price': latest['Close'],
                                'entry_idx': i,
                                'stop_loss': latest['Close'] + (2 * latest['ATR']),
                                'target': latest['Close'] - (3 * latest['ATR']),
                                'wave': elliott['wave']
                            }
            
            # Exit logic
            elif position is not None:
                current_price = latest['Close']
                entry_price = position['entry_price']
                
                exit_trade = False
                exit_reason = None
                
                if position['type'] == 'LONG':
                    if current_price >= position['target']:
                        exit_trade = True
                        exit_reason = 'TARGET'
                    elif current_price <= position['stop_loss']:
                        exit_trade = True
                        exit_reason = 'STOP_LOSS'
                    elif score < -1:  # Signal reversal
                        exit_trade = True
                        exit_reason = 'SIGNAL_REVERSAL'
                    elif wave_bias == 'SELL':  # Elliott Wave reversal
                        exit_trade = True
                        exit_reason = 'ELLIOTT_REVERSAL'
                else:  # SHORT
                    if current_price <= position['target']:
                        exit_trade = True
                        exit_reason = 'TARGET'
                    elif current_price >= position['stop_loss']:
                        exit_trade = True
                        exit_reason = 'STOP_LOSS'
                    elif score > 1:
                        exit_trade = True
                        exit_reason = 'SIGNAL_REVERSAL'
                    elif wave_bias == 'BUY':
                        exit_trade = True
                        exit_reason = 'ELLIOTT_REVERSAL'
                
                if exit_trade:
                    if position['type'] == 'LONG':
                        pnl = current_price - entry_price
                    else:
                        pnl = entry_price - current_price
                    
                    pnl_pct = (pnl / entry_price) * 100
                    capital += (capital * pnl_pct / 100)
                    
                    trades.append({
                        'entry': entry_price,
                        'exit': current_price,
                        'pnl': pnl,
                        'pnl_pct': pnl_pct,
                        'type': position['type'],
                        'reason': exit_reason,
                        'wave': position.get('wave', 'N/A')
                    })
                    
                    position = None
            
            equity_curve.append(capital)
        
        # Calculate statistics
        if not trades:
            return BacktestResult(0, 0, 0, 0, 0, 0, 0, 0, 0)
        
        total_trades = len(trades)
        winning_trades = len([t for t in trades if t['pnl'] > 0])
        losing_trades = len([t for t in trades if t['pnl'] <= 0])
        win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0
        
        profits = [t['pnl_pct'] for t in trades if t['pnl'] > 0]
        losses = [abs(t['pnl_pct']) for t in trades if t['pnl'] <= 0]
        
        avg_profit = np.mean(profits) if profits else 0
        avg_loss = np.mean(losses) if losses else 0
        
        total_profit = sum(profits)
        total_loss = sum(losses)
        profit_factor = (total_profit / total_loss) if total_loss > 0 else 0
        
        # Max drawdown
        equity_array = np.array(equity_curve)
        running_max = np.maximum.accumulate(equity_array)
        drawdown = (equity_array - running_max) / running_max * 100
        max_drawdown = abs(np.min(drawdown))
        
        total_return = ((capital - initial_capital) / initial_capital) * 100
        
        return BacktestResult(
            total_trades=total_trades,
            winning_trades=winning_trades,
            losing_trades=losing_trades,
            win_rate=win_rate,
            avg_profit=avg_profit,
            avg_loss=avg_loss,
            profit_factor=profit_factor,
            max_drawdown=max_drawdown,
            total_return=total_return
        )

class DataFetcher:
    """Handles data fetching with rate limiting"""
    
    @staticmethod
    def fetch_data(ticker: str, period: str, interval: str) -> pd.DataFrame:
        """Fetch data with rate limiting and error handling"""
        
        cache_key = f"{ticker}_{period}_{interval}"
        current_time = time.time()
        
        # Check cache (5 minutes validity)
        if cache_key in st.session_state.data_cache:
            cached_data, cache_time = st.session_state.data_cache[cache_key]
            if current_time - cache_time < 300:  # 5 minutes
                return cached_data
        
        # Rate limiting
        if cache_key in st.session_state.last_fetch_time:
            time_since_last = current_time - st.session_state.last_fetch_time[cache_key]
            if time_since_last < 1.5:
                time.sleep(1.5 - time_since_last)
        
        try:
            # Fetch data
            stock = yf.Ticker(ticker)
            df = stock.history(period=period, interval=interval)
            
            if df.empty:
                st.error(f"No data available for {ticker}")
                return pd.DataFrame()
            
            # Convert to IST
            if df.index.tz is not None:
                df.index = df.index.tz_convert('Asia/Kolkata')
            else:
                df.index = df.index.tz_localize('UTC').tz_convert('Asia/Kolkata')
            
            # Fetch news
            try:
                news = stock.news[:5] if hasattr(stock, 'news') else []
                df.attrs['news'] = news
            except:
                df.attrs['news'] = []
            
            # Cache data
            st.session_state.data_cache[cache_key] = (df, current_time)
            st.session_state.last_fetch_time[cache_key] = current_time
            
            return df
            
        except Exception as e:
            st.error(f"Error fetching data: {str(e)}")
            return pd.DataFrame()

def plot_advanced_chart(df: pd.DataFrame, signal: TradingSignal):
    """Create advanced trading chart with indicators, Elliott Waves, and Fibonacci"""
    
    fig = make_subplots(
        rows=4, cols=1,
        shared_xaxes=True,
        vertical_spacing=0.02,
        subplot_titles=('Price, Elliott Wave & Fibonacci', 'MACD', 'RSI', 'Volume'),
        row_heights=[0.5, 0.15, 0.15, 0.2]
    )
    
    # Candlestick chart
    fig.add_trace(go.Candlestick(
        x=df.index,
        open=df['Open'],
        high=df['High'],
        low=df['Low'],
        close=df['Close'],
        name='Price'
    ), row=1, col=1)
    
    # Moving Averages
    fig.add_trace(go.Scatter(x=df.index, y=df['SMA_20'], name='SMA 20',
                            line=dict(color='orange', width=1)), row=1, col=1)
    fig.add_trace(go.Scatter(x=df.index, y=df['SMA_50'], name='SMA 50',
                            line=dict(color='blue', width=1)), row=1, col=1)
    if 'SMA_200' in df.columns:
        fig.add_trace(go.Scatter(x=df.index, y=df['SMA_200'], name='SMA 200',
                                line=dict(color='purple', width=1)), row=1, col=1)
    
    # Bollinger Bands
    fig.add_trace(go.Scatter(x=df.index, y=df['BB_Upper'], name='BB Upper',
                            line=dict(color='gray', width=1, dash='dash')), row=1, col=1)
    fig.add_trace(go.Scatter(x=df.index, y=df['BB_Lower'], name='BB Lower',
                            line=dict(color='gray', width=1, dash='dash'),
                            fill='tonexty', fillcolor='rgba(128,128,128,0.1)'), row=1, col=1)
    
    # Fibonacci Levels
    try:
        fib_analysis = FibonacciAnalyzer.calculate_fibonacci_levels(df)
        for level_name, level_value in fib_analysis['levels'].items():
            if level_name in ['38.2%', '50%', '61.8%']:  # Show key Fib levels
                fig.add_hline(y=level_value, line_dash="dot", line_color="gold",
                             annotation_text=f"Fib {level_name}", 
                             annotation_position="right",
                             row=1, col=1, opacity=0.5)
    except:
        pass
    
    # Elliott Wave Pivots
    try:
        elliott = ElliottWaveAnalyzer.detect_elliott_wave(df)
        if elliott['confidence'] > 60:
            # Add text annotation for current wave
            latest_time = df.index[-1]
            latest_price = df['Close'].iloc[-1]
            fig.add_annotation(
                x=latest_time,
                y=latest_price,
                text=f"<b>{elliott['wave']}</b>",
                showarrow=True,
                arrowhead=2,
                arrowsize=1,
                arrowwidth=2,
                arrowcolor="purple",
                ax=40,
                ay=-40,
                font=dict(size=12, color="purple"),
                bgcolor="rgba(255,255,255,0.8)",
                row=1, col=1
            )
    except:
        pass
    
    # Entry, Target, Stop Loss lines
    latest_time = df.index[-1]
    if signal.action in ["BUY", "SELL"]:
        fig.add_hline(y=signal.entry_price, line_dash="solid", line_color="blue",
                     annotation_text="Entry", row=1, col=1)
        fig.add_hline(y=signal.target_price, line_dash="dash", line_color="green",
                     annotation_text="Target", row=1, col=1)
        fig.add_hline(y=signal.stop_loss, line_dash="dash", line_color="red",
                     annotation_text="Stop Loss", row=1, col=1)
    
    # MACD
    if 'MACD' in df.columns:
        fig.add_trace(go.Scatter(x=df.index, y=df['MACD'], name='MACD',
                                line=dict(color='blue', width=1)), row=2, col=1)
        fig.add_trace(go.Scatter(x=df.index, y=df['MACD_Signal'], name='Signal',
                                line=dict(color='red', width=1)), row=2, col=1)
        
        colors = ['green' if val >= 0 else 'red' for val in df['MACD_Hist']]
        fig.add_trace(go.Bar(x=df.index, y=df['MACD_Hist'], name='Histogram',
                            marker_color=colors), row=2, col=1)
    
    # RSI
    if 'RSI' in df.columns:
        fig.add_trace(go.Scatter(x=df.index, y=df['RSI'], name='RSI',
                                line=dict(color='purple', width=2)), row=3, col=1)
        fig.add_hline(y=70, line_dash="dash", line_color="red", row=3, col=1)
        fig.add_hline(y=30, line_dash="dash", line_color="green", row=3, col=1)
        fig.add_hrect(y0=30, y1=70, fillcolor="gray", opacity=0.1, row=3, col=1)
    
    # Volume
    if 'Volume' in df.columns and df['Volume'].sum() > 0:
        volume_colors = ['green' if df['Close'].iloc[i] >= df['Open'].iloc[i] 
                        else 'red' for i in range(len(df))]
        fig.add_trace(go.Bar(x=df.index, y=df['Volume'], name='Volume',
                            marker_color=volume_colors), row=4, col=1)
    
    # Layout
    fig.update_layout(
        title=f"Technical Analysis Chart - {signal.strategy} | Elliott Wave: {elliott.get('wave', 'N/A') if 'elliott' in locals() else 'N/A'}",
        xaxis_rangeslider_visible=False,
        height=1000,
        showlegend=True,
        hovermode='x unified'
    )
    
    fig.update_xaxes(title_text="Date", row=4, col=1)
    fig.update_yaxes(title_text="Price", row=1, col=1)
    fig.update_yaxes(title_text="MACD", row=2, col=1)
    fig.update_yaxes(title_text="RSI", row=3, col=1)
    fig.update_yaxes(title_text="Volume", row=4, col=1)
    
    return fig

def main():
    """Main application"""
    
    # Header
    st.markdown('<h1 class="main-header">ðŸ“ˆ Professional Multi-Timeframe Trading System</h1>', 
                unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ Configuration")
        
        # Instrument Selection
        instrument = st.selectbox("Select Instrument", list(INSTRUMENTS.keys()))
        
        if instrument == "Custom Ticker":
            custom_ticker = st.text_input("Enter Ticker Symbol", "RELIANCE.NS")
            ticker = custom_ticker
        else:
            ticker = INSTRUMENTS[instrument]
        
        st.markdown("---")
        
        # Trading Style
        trading_style = st.selectbox(
            "Trading Style",
            ["Day Trading", "Swing Trading", "Scalping", "Positional Trading"]
        )
        
        # Timeframe
        timeframe = st.selectbox("Timeframe", TIMEFRAMES, index=4)
        
        # Period
        period = st.selectbox("Period", PERIODS, index=5)
        
        st.markdown("---")
        
        # Ratio Analysis Options
        st.subheader("ðŸ“Š Ratio Analysis")
        include_ratio = st.checkbox("Include Ratio Analysis", value=True)
        
        if include_ratio:
            ratio_instrument = st.selectbox(
                "Compare with Instrument",
                list(INSTRUMENTS.keys()),
                index=0,
                key="ratio_instrument"
            )
            
            if ratio_instrument == "Custom Ticker":
                ratio_ticker = st.text_input(
                    "Enter Comparison Ticker", 
                    value="^NSEI",
                    help="Enter ticker to compare"
                )
            else:
                ratio_ticker = INSTRUMENTS[ratio_instrument]
        else:
            ratio_ticker = None
        
        st.markdown("---")
        
        # Optimization Settings
        st.subheader("ðŸŽ¯ Optimization")
        target_annual_return = st.slider(
            "Target Annual Return (%)", 
            min_value=10, 
            max_value=50, 
            value=20,
            help="System will optimize to achieve this return"
        )
        
        st.markdown("---")
        
        # API Rate Limiting
        api_delay = st.slider("API Delay (seconds)", 1.0, 5.0, 1.5, 0.5)
        
        st.markdown("---")
        
        # Fetch Data Button
        fetch_button = st.button("ðŸ”„ Fetch & Analyze", type="primary", use_container_width=True)
        
        st.markdown("---")
        st.info("âš ï¸ **Risk Disclaimer**: This tool is for educational purposes. Always do your own research and consult with financial advisors.")
    
    # Main Content
    if fetch_button:
        strategy_engine = StrategyEngine()  # Initialize here at the start
        
        with st.spinner("ðŸ” Fetching market data..."):
            # Fetch data with delay
            time.sleep(api_delay)
            df = DataFetcher.fetch_data(ticker, period, timeframe)
            
            if df.empty:
                st.error("Unable to fetch data. Please check the ticker symbol and try again.")
                return
            
            st.success(f"âœ… Data fetched successfully! ({len(df)} candles)")
        
        with st.spinner("ðŸ§® Calculating technical indicators..."):
            # Calculate indicators
            df = TechnicalAnalyzer.calculate_indicators(df)
        
        with st.spinner("ðŸ“Š Analyzing multiple timeframes..."):
            # Multi-timeframe analysis
            timeframe_signals = strategy_engine.analyze_multiple_timeframes(
                ticker, period, trading_style
            )
        
        with st.spinner("ðŸŽ¯ Optimizing strategy parameters..."):
            # Optimize for target returns
            best_strategy = strategy_engine.select_best_strategy(df, trading_style)
            
            # Run optimization with proper error handling
            try:
                optimization_result = BacktestEngine.optimize_strategy_parameters(
                    df, best_strategy, target_annual_return=target_annual_return
                )
                
                if optimization_result['optimized']:
                    st.success(f"âœ… Strategy optimized! {optimization_result['message']}")
                else:
                    st.warning(f"âš ï¸ {optimization_result['message']}")
                    # Still use the best found parameters even if not fully optimized
            except Exception as e:
                st.warning(f"âš ï¸ Optimization encountered an issue: {str(e)}. Using default parameters.")
                optimization_result = {
                    'optimized': False,
                    'best_params': None,
                    'annual_return': 0,
                    'message': 'Using default parameters'
                }
        
        with st.spinner("ðŸŽ¯ Generating trading signals..."):
            # Generate signals with optimized parameters
            signal = strategy_engine.generate_signal(
                df, best_strategy, trading_style, ticker, timeframe_signals,
                ratio_ticker=ratio_ticker if include_ratio else None
            )
            
            # Volatility analysis
            volatility_analysis = VolatilityAnalyzer.analyze_volatility(df)
            
            # All support/resistance levels
            all_sr_levels = SupportResistanceAnalyzer.find_all_strong_levels(df)
            
            # Store in session state
            st.session_state.analysis_results = {
                'df': df,
                'signal': signal,
                'strategy': best_strategy,
                'ticker': ticker,
                'instrument': instrument,
                'timeframe_signals': timeframe_signals,
                'volatility': volatility_analysis,
                'all_sr_levels': all_sr_levels,
                'optimization': optimization_result,
                'timeframe': timeframe,
                'ratio_ticker': ratio_ticker if include_ratio else None,
                'include_ratio': include_ratio
            }
        
        st.success("âœ… Analysis complete!")
    
    # Display Results
    if st.session_state.analysis_results is not None:
        results = st.session_state.analysis_results
        df = results['df']
        signal = results['signal']
        strategy = results['strategy']
        ticker = results['ticker']
        instrument = results['instrument']
        timeframe_signals = results.get('timeframe_signals', {})
        volatility = results.get('volatility')
        all_sr_levels = results.get('all_sr_levels', {})
        optimization = results.get('optimization', {})
        current_timeframe = results.get('timeframe', '15m')
        ratio_ticker = results.get('ratio_ticker')
        
        # Optimization Status
        if optimization:
            if optimization['optimized']:
                st.success(f"ðŸŽ¯ **Strategy Optimized**: Achieving {optimization['annual_return']:.2f}% annual return (Target: {target_annual_return}%)")
            else:
                st.warning(f"âš ï¸ **Optimization Result**: {optimization['message']}")
        
        # Signal Box
        signal_class = {
            'BUY': 'buy-signal',
            'SELL': 'sell-signal',
            'HOLD': 'hold-signal'
        }[signal.action]
        
        st.markdown(f"""
        <div class="signal-box {signal_class}">
            ðŸŽ¯ Signal: {signal.action} | Confidence: {signal.confidence:.1f}% | Strategy: {signal.strategy}
        </div>
        """, unsafe_allow_html=True)
        
        # Key Metrics
        col1, col2, col3, col4, col5, col6 = st.columns(6)
        
        with col1:
            st.metric("Current Price", f"â‚¹{signal.entry_price:.2f}")
        
        with col2:
            target_change = ((signal.target_price - signal.entry_price) / signal.entry_price) * 100
            st.metric("Target Price", f"â‚¹{signal.target_price:.2f}", 
                     f"{target_change:+.2f}%")
        
        with col3:
            sl_change = ((signal.stop_loss - signal.entry_price) / signal.entry_price) * 100
            st.metric("Stop Loss", f"â‚¹{signal.stop_loss:.2f}", 
                     f"{sl_change:.2f}%")
        
        with col4:
            st.metric("Risk:Reward", f"1:{signal.risk_reward:.2f}")
        
        with col5:
            latest = df.iloc[-1]
            st.metric("RSI", f"{latest['RSI']:.1f}")
        
        with col6:
            if volatility:
                st.metric("Volatility", volatility.volatility_regime)
        
        # Volatility Analysis Section
        if volatility:
            st.markdown("---")
            st.subheader("ðŸ“Š Volatility Analysis & Impact")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Historical Volatility", f"{volatility.historical_volatility:.2f}%",
                         help="Annualized volatility based on price returns")
            
            with col2:
                st.metric("ATR Volatility", f"{volatility.atr_volatility:.2f}%",
                         help="Current ATR as percentage of price")
            
            with col3:
                st.metric("Volatility Percentile", f"{volatility.volatility_percentile:.1f}%",
                         help="Current volatility vs historical distribution")
            
            if volatility.volatility_regime == "EXTREME HIGH":
                st.error(f"ðŸ”¥ **{volatility.volatility_regime} VOLATILITY**: {volatility.impact_on_trading}")
            elif volatility.volatility_regime == "HIGH":
                st.warning(f"âš ï¸ **{volatility.volatility_regime} VOLATILITY**: {volatility.impact_on_trading}")
            elif volatility.volatility_regime == "LOW":
                st.info(f"ðŸ“‰ **{volatility.volatility_regime} VOLATILITY**: {volatility.impact_on_trading}")
            else:
                st.success(f"âœ… **{volatility.volatility_regime} VOLATILITY**: {volatility.impact_on_trading}")
        
        # Multiple Support/Resistance Levels
        st.markdown("---")
        st.subheader("ðŸŽšï¸ All Strong Support & Resistance Levels")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ðŸŸ¢ Support Levels:**")
            if all_sr_levels.get('supports'):
                for i, support in enumerate(all_sr_levels['supports'], 1):
                    distance = ((signal.entry_price - support['price']) / signal.entry_price) * 100
                    st.write(f"{i}. â‚¹{support['price']:.2f} - {support['strength']} ({distance:.2f}% below)")
                    st.caption(f"   Last tested: {support['dates'][-1].strftime('%Y-%m-%d')}")
            else:
                st.info("No strong support levels identified")
        
        with col2:
            st.markdown("**ðŸ”´ Resistance Levels:**")
            if all_sr_levels.get('resistances'):
                for i, resistance in enumerate(all_sr_levels['resistances'], 1):
                    distance = ((resistance['price'] - signal.entry_price) / signal.entry_price) * 100
                    st.write(f"{i}. â‚¹{resistance['price']:.2f} - {resistance['strength']} ({distance:.2f}% above)")
                    st.caption(f"   Last tested: {resistance['dates'][-1].strftime('%Y-%m-%d')}")
            else:
                st.info("No strong resistance levels identified")
        
        # Detailed Summary
        st.markdown("---")
        st.subheader("ðŸ“‹ Detailed 200-Word Market Analysis")
        st.markdown(signal.detailed_summary)
        
        # Pattern Reliability Section (NEW - CRITICAL)
        st.markdown("---")
        st.subheader("ðŸŽ¯ Pattern Reliability Analysis (What's Working NOW)")
        st.info("**Critical Insight**: This section shows which technical patterns the market is following most reliably. We test each pattern's historical accuracy and weight our signals accordingly.")
        
        with st.spinner("Analyzing pattern reliability..."):
            pattern_reliability = PatternReliabilityAnalyzer.analyze_pattern_reliability(df)
        
        if pattern_reliability['most_reliable'] != 'INSUFFICIENT_DATA':
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown("**ðŸ“Š Pattern Performance Rankings:**")
                sorted_patterns = sorted(pattern_reliability['reliability_scores'].items(), 
                                       key=lambda x: x[1], reverse=True)
                
                for i, (pattern, score) in enumerate(sorted_patterns, 1):
                    if score > 70:
                        color = "green"
                        badge = "ðŸŸ¢ HIGHLY RELIABLE"
                    elif score > 55:
                        color = "orange"
                        badge = "ðŸŸ¡ MODERATELY RELIABLE"
                    else:
                        color = "red"
                        badge = "ðŸ”´ UNRELIABLE"
                    
                    st.markdown(f"{i}. **{pattern}**: <span style='color:{color};font-weight:bold'>{score:.1f}%</span> {badge}", unsafe_allow_html=True)
            
            with col2:
                # Create gauge chart for most reliable pattern
                most_reliable = pattern_reliability['most_reliable']
                reliability_score = pattern_reliability['reliability_scores'][most_reliable]
                
                gauge_fig = go.Figure(go.Indicator(
                    mode = "gauge+number",
                    value = reliability_score,
                    domain = {'x': [0, 1], 'y': [0, 1]},
                    title = {'text': f"{most_reliable}<br>Accuracy"},
                    gauge = {
                        'axis': {'range': [None, 100]},
                        'bar': {'color': "darkblue"},
                        'steps': [
                            {'range': [0, 50], 'color': "lightgray"},
                            {'range': [50, 70], 'color': "lightyellow"},
                            {'range': [70, 100], 'color': "lightgreen"}
                        ],
                        'threshold': {
                            'line': {'color': "red", 'width': 4},
                            'thickness': 0.75,
                            'value': 70
                        }
                    }
                ))
                gauge_fig.update_layout(height=300)
                st.plotly_chart(gauge_fig, use_container_width=True)
            
            st.markdown("**ðŸ’¡ Interpretation:**")
            st.success(f"The market is currently following **{most_reliable}** most reliably ({reliability_score:.1f}% accuracy). This pattern receives the highest weight in our signal generation.")
            
            st.markdown("**ðŸ“š Recommendations:**")
            for rec in pattern_reliability['recommendations']:
                st.write(rec)
        
        else:
            st.warning("Insufficient data to analyze pattern reliability")
        
        # Multi-Timeframe Confluence
        if timeframe_signals:
            st.markdown("---")
            st.subheader("â±ï¸ Multi-Timeframe Analysis & Signal Confluence")
            st.markdown(signal.signal_confluence)
        
        # Support & Resistance Analysis
        st.markdown("---")
        st.subheader("ðŸŽšï¸ Strong Support & Resistance Levels")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ðŸŸ¢ Strong Support Level**")
            st.metric("Support Price", f"â‚¹{signal.strong_support:.2f}")
            st.info(f"**Analysis:** {signal.support_strength}")
        
        with col2:
            st.markdown("**ðŸ”´ Strong Resistance Level**")
            st.metric("Resistance Price", f"â‚¹{signal.strong_resistance:.2f}")
            st.info(f"**Analysis:** {signal.resistance_strength}")
        
        # Z-Score Analysis
        st.markdown("---")
        st.subheader("ðŸ“Š Z-Score Analysis (Mean Reversion)")
        
        col1, col2 = st.columns(2)
        
        with col1:
            zscore_color = "green" if abs(signal.zscore) < 1 else ("orange" if abs(signal.zscore) < 2 else "red")
            st.markdown(f"**Current Z-Score:** <span style='color:{zscore_color};font-size:24px;font-weight:bold'>{signal.zscore:.2f}</span>", unsafe_allow_html=True)
            st.write(f"**Interpretation:** {signal.zscore_interpretation}")
        
        with col2:
            # Z-Score visualization
            z_fig = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = signal.zscore,
                domain = {'x': [0, 1], 'y': [0, 1]},
                gauge = {
                    'axis': {'range': [-3, 3]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [-3, -2], 'color': "lightgreen"},
                        {'range': [-2, -1], 'color': "lightblue"},
                        {'range': [-1, 1], 'color': "lightyellow"},
                        {'range': [1, 2], 'color': "lightcoral"},
                        {'range': [2, 3], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "black", 'width': 4},
                        'thickness': 0.75,
                        'value': signal.zscore
                    }
                },
                title = {'text': "Z-Score Gauge"}
            ))
            z_fig.update_layout(height=250)
            st.plotly_chart(z_fig, use_container_width=True)
        
        # Sentiment Analysis
        st.markdown("---")
        st.subheader("ðŸ“° News Sentiment Analysis")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            sentiment_color = "green" if signal.sentiment_score > 0.15 else ("red" if signal.sentiment_score < -0.15 else "gray")
            st.markdown(f"**Sentiment Score:** <span style='color:{sentiment_color};font-size:24px;font-weight:bold'>{signal.sentiment_score:.3f}</span>", unsafe_allow_html=True)
            st.write(f"**Summary:** {signal.sentiment_summary}")
        
        with col2:
            st.markdown("**Recent News Headlines:**")
            sentiment_analyzer = SentimentAnalyzer(ticker)
            sentiment_data = sentiment_analyzer.analyze()
            
            if sentiment_data.get('details'):
                for item in sentiment_data['details'][:3]:
                    score = item['score']
                    emoji = "ðŸŸ¢" if score > 0.1 else ("ðŸ”´" if score < -0.1 else "ðŸŸ¡")
                    st.markdown(f"{emoji} **{item['title']}** (Sentiment: {score:.2f})")
            else:
                st.info("No recent news available")
        
        # Analysis Reasoning
        st.markdown("---")
        st.subheader("ðŸ“Š Technical Analysis Reasoning")
        st.markdown(signal.reasoning)
        
        # Chart
        st.markdown("---")
        st.subheader("ðŸ“ˆ Technical Chart")
        chart = plot_advanced_chart(df, signal)
        st.plotly_chart(chart, use_container_width=True)
        
        # Backtesting Section
        st.markdown("---")
        st.subheader("ðŸ”¬ Backtest Validation with Optimization")
        
        with st.spinner("Running optimized backtest..."):
            backtest_engine = BacktestEngine()
            
            # Run with optimized parameters
            if optimization and optimization.get('best_params'):
                backtest_result = backtest_engine.run_backtest(
                    df, strategy, params=optimization['best_params']
                )
            else:
                backtest_result = backtest_engine.run_backtest(df, strategy)
        
        # Display optimization parameters
        if optimization and optimization.get('best_params'):
            st.info(f"**Optimized Parameters Applied**: Entry Threshold={optimization['best_params']['entry_threshold']}, "
                   f"Stop Loss={optimization['best_params']['stop_loss_atr']}x ATR, "
                   f"Take Profit={optimization['best_params']['take_profit_atr']}x ATR")
        
        # More lenient validation - check if we have ANY trades and positive metrics
        has_trades = backtest_result.total_trades > 0
        is_profitable = backtest_result.total_return > 0 or backtest_result.win_rate >= 40
        
        # Calculate a confidence score based on backtest
        backtest_confidence = 0
        if has_trades:
            if backtest_result.win_rate >= 50:
                backtest_confidence += 30
            elif backtest_result.win_rate >= 40:
                backtest_confidence += 20
            else:
                backtest_confidence += 10
            
            if backtest_result.total_return > 0:
                backtest_confidence += 30
            
            if backtest_result.profit_factor > 1.5:
                backtest_confidence += 20
            elif backtest_result.profit_factor > 1.0:
                backtest_confidence += 10
            
            if backtest_result.annual_return >= target_annual_return:
                backtest_confidence += 20
        
        if is_profitable and has_trades:
            st.success(f"âœ… **STRATEGY VALIDATED**: {backtest_result.total_trades} trades, "
                      f"{backtest_result.win_rate:.1f}% win rate, "
                      f"{backtest_result.annual_return:.2f}% annual return")
        elif has_trades:
            st.warning(f"âš ï¸ **MIXED RESULTS**: {backtest_result.total_trades} trades generated. "
                      f"Win rate: {backtest_result.win_rate:.1f}%, Annual return: {backtest_result.annual_return:.2f}%")
            st.info("ðŸ’¡ Signal generated with REDUCED confidence due to mixed backtest results.")
            
            # Reduce signal confidence but don't override to HOLD
            signal.confidence = signal.confidence * 0.7
            signal.reasoning += f"\n\nâš ï¸ **BACKTEST NOTE**: Historical results show {backtest_result.win_rate:.1f}% win rate " \
                               f"and {backtest_result.annual_return:.2f}% annual return. Use with caution and smaller position size."
        else:
            st.error(f"âš ï¸ **NO TRADES GENERATED**: Backtest produced {backtest_result.total_trades} trades. "
                    "Parameters may be too strict or insufficient data.")
            st.warning("**RECOMMENDATION**: Signal generated but consider this as LOWER CONFIDENCE due to limited backtest data.")
            
            # Reduce confidence significantly but still show signal
            signal.confidence = signal.confidence * 0.5
            signal.reasoning += f"\n\nâš ï¸ **BACKTEST LIMITATION**: No historical trades generated with these parameters. " \
                               f"This could indicate very strict entry criteria or insufficient data. Use extreme caution."
        
        if backtest_result.total_trades > 0:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.metric("Total Trades", backtest_result.total_trades)
                st.metric("Win Rate", f"{backtest_result.win_rate:.1f}%")
                st.metric("Total Return", f"{backtest_result.total_return:.2f}%")
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.metric("Winning Trades", backtest_result.winning_trades)
                st.metric("Losing Trades", backtest_result.losing_trades)
                st.metric("Profit Factor", f"{backtest_result.profit_factor:.2f}")
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col3:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.metric("Avg Profit", f"{backtest_result.avg_profit:.2f}%")
                st.metric("Avg Loss", f"{backtest_result.avg_loss:.2f}%")
                st.metric("Max Drawdown", f"{backtest_result.max_drawdown:.2f}%")
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col4:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                annual_delta = backtest_result.annual_return - target_annual_return
                st.metric("Annual Return", f"{backtest_result.annual_return:.2f}%",
                         delta=f"{annual_delta:+.2f}% vs target")
                st.metric("Sharpe Ratio", f"{backtest_result.sharpe_ratio:.2f}")
                st.metric("Backtest Confidence", f"{backtest_confidence}%")
                st.markdown('</div>', unsafe_allow_html=True)
            
            # Backtest interpretation
            st.markdown("---")
            st.subheader("ðŸŽ“ Backtest Interpretation")
            
            if backtest_result.win_rate >= 60:
                st.success(f"âœ… **Strong Strategy**: {backtest_result.win_rate:.1f}% win rate indicates reliable performance")
            elif backtest_result.win_rate >= 50:
                st.warning(f"âš ï¸ **Moderate Strategy**: {backtest_result.win_rate:.1f}% win rate - use with caution")
            else:
                st.error(f"âŒ **Weak Strategy**: {backtest_result.win_rate:.1f}% win rate - not recommended")
            
            if backtest_result.profit_factor >= 2:
                st.success(f"âœ… **Excellent Risk/Reward**: Profit factor of {backtest_result.profit_factor:.2f}")
            elif backtest_result.profit_factor >= 1.5:
                st.info(f"â„¹ï¸ **Good Risk/Reward**: Profit factor of {backtest_result.profit_factor:.2f}")
            else:
                st.warning(f"âš ï¸ **Poor Risk/Reward**: Profit factor of {backtest_result.profit_factor:.2f}")
            
            if backtest_result.max_drawdown < 10:
                st.success(f"âœ… **Low Risk**: Maximum drawdown of {backtest_result.max_drawdown:.2f}%")
            elif backtest_result.max_drawdown < 20:
                st.warning(f"âš ï¸ **Moderate Risk**: Maximum drawdown of {backtest_result.max_drawdown:.2f}%")
            else:
                st.error(f"âŒ **High Risk**: Maximum drawdown of {backtest_result.max_drawdown:.2f}%")
        else:
            st.warning("âš ï¸ Not enough data for backtesting. Need at least 100 candles.")
        
        # Market Conditions
        st.markdown("---")
        st.subheader("ðŸŒ Current Market Conditions")
        
        latest = df.iloc[-1]
        market_structure = strategy_engine.detect_market_structure(df)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Technical Indicators:**")
            st.write(f"â€¢ Market Structure: **{market_structure.replace('_', ' ').title()}**")
            st.write(f"â€¢ RSI: **{latest['RSI']:.2f}**")
            st.write(f"â€¢ MACD: **{latest['MACD']:.4f}**")
            st.write(f"â€¢ ADX: **{latest['ADX']:.2f}**")
            st.write(f"â€¢ ATR: **{latest['ATR']:.2f}**")
        
        with col2:
            st.markdown("**Price Levels:**")
            st.write(f"â€¢ Support: **â‚¹{latest['Support']:.2f}**")
            st.write(f"â€¢ Resistance: **â‚¹{latest['Resistance']:.2f}**")
            st.write(f"â€¢ BB Upper: **â‚¹{latest['BB_Upper']:.2f}**")
            st.write(f"â€¢ BB Lower: **â‚¹{latest['BB_Lower']:.2f}**")
            st.write(f"â€¢ Volume Ratio: **{latest['Volume_Ratio']:.2f}x**")
        
        # Trading Psychology Section
        st.markdown("---")
        st.subheader("ðŸ§  Trading Psychology Guide")
        
        with st.expander("ðŸ“š Essential Trading Psychology Tips"):
            st.markdown("""
            **1. Emotional Control:**
            - Fear and greed are your biggest enemies
            - Stick to your trading plan, don't deviate
            - Accept that losses are part of trading
            
            **2. Risk Management:**
            - Never risk more than 1-2% per trade
            - Always use stop losses
            - Position sizing is crucial
            
            **3. Discipline:**
            - Wait for high-probability setups
            - Don't overtrade - patience is key
            - Keep a trading journal
            
            **4. Avoid Common Mistakes:**
            - Revenge trading after losses
            - Moving stop losses when price goes against you
            - Holding losing positions hoping for recovery
            - FOMO (Fear of Missing Out)
            
            **5. Success Mindset:**
            - Focus on the process, not just profits
            - Continuous learning and improvement
            - Accept responsibility for all trades
            - Stay humble and respect the market
            """)
        
        # Comprehensive Data Table
        st.markdown("---")
        st.subheader("ðŸ“Š Comprehensive Analysis Data Table")
        
        # Prepare comprehensive table data
        table_data = []
        
        # Get Fibonacci levels with actual prices
        fib_analysis = FibonacciAnalyzer.calculate_fibonacci_levels(df)
        
        # Current data
        latest = df.iloc[-1]
        current_time = latest.name if hasattr(latest.name, 'strftime') else datetime.now()
        
        # Add rows for different metrics
        table_data.append({
            'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
            'Timeframe': current_timeframe,
            'Ticker': ticker,
            'Metric': 'Current Price',
            'Value': f"â‚¹{latest['Close']:.2f}",
            'Details': f"Open: â‚¹{latest['Open']:.2f}, High: â‚¹{latest['High']:.2f}, Low: â‚¹{latest['Low']:.2f}"
        })
        
        # Technical Indicators
        table_data.append({
            'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
            'Timeframe': current_timeframe,
            'Ticker': ticker,
            'Metric': 'RSI',
            'Value': f"{latest['RSI']:.2f}",
            'Details': 'Overbought >70, Oversold <30'
        })
        
        table_data.append({
            'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
            'Timeframe': current_timeframe,
            'Ticker': ticker,
            'Metric': 'MACD',
            'Value': f"{latest['MACD']:.4f}",
            'Details': f"Signal: {latest['MACD_Signal']:.4f}, Hist: {latest['MACD_Hist']:.4f}"
        })
        
        table_data.append({
            'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
            'Timeframe': current_timeframe,
            'Ticker': ticker,
            'Metric': 'ADX',
            'Value': f"{latest['ADX']:.2f}",
            'Details': '>25 indicates strong trend'
        })
        
        table_data.append({
            'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
            'Timeframe': current_timeframe,
            'Ticker': ticker,
            'Metric': 'ATR',
            'Value': f"â‚¹{latest['ATR']:.2f}",
            'Details': f"{volatility.atr_volatility:.2f}% of price" if volatility else "N/A"
        })
        
        # Moving Averages
        table_data.append({
            'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
            'Timeframe': current_timeframe,
            'Ticker': ticker,
            'Metric': 'Moving Averages',
            'Value': f"SMA20: â‚¹{latest['SMA_20']:.2f}",
            'Details': f"SMA50: â‚¹{latest['SMA_50']:.2f}, SMA200: â‚¹{latest.get('SMA_200', 'N/A')}"
        })
        
        # Fibonacci Levels
        for level_name, level_value in fib_analysis['levels'].items():
            if level_name in ['38.2%', '50%', '61.8%']:
                distance = ((latest['Close'] - level_value) / latest['Close']) * 100
                table_data.append({
                    'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
                    'Timeframe': current_timeframe,
                    'Ticker': ticker,
                    'Metric': f'Fibonacci {level_name}',
                    'Value': f"â‚¹{level_value:.2f}",
                    'Details': f"{distance:+.2f}% from current price"
                })
        
        # Support/Resistance
        if all_sr_levels.get('supports'):
            for i, support in enumerate(all_sr_levels['supports'][:3], 1):
                table_data.append({
                    'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
                    'Timeframe': current_timeframe,
                    'Ticker': ticker,
                    'Metric': f'Support Level {i}',
                    'Value': f"â‚¹{support['price']:.2f}",
                    'Details': f"{support['strength']}, {support['distance']:.2f}% below"
                })
        
        if all_sr_levels.get('resistances'):
            for i, resistance in enumerate(all_sr_levels['resistances'][:3], 1):
                table_data.append({
                    'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
                    'Timeframe': current_timeframe,
                    'Ticker': ticker,
                    'Metric': f'Resistance Level {i}',
                    'Value': f"â‚¹{resistance['price']:.2f}",
                    'Details': f"{resistance['strength']}, {resistance['distance']:.2f}% above"
                })
        
        # Volatility
        if volatility:
            table_data.append({
                'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
                'Timeframe': current_timeframe,
                'Ticker': ticker,
                'Metric': 'Volatility',
                'Value': f"{volatility.historical_volatility:.2f}%",
                'Details': f"Regime: {volatility.volatility_regime}, Percentile: {volatility.volatility_percentile:.1f}%"
            })
        
        # Volume (if available)
        if 'Volume' in df.columns and df['Volume'].sum() > 0:
            vol_ratio = latest['Volume'] / df['Volume'].rolling(20).mean().iloc[-1]
            table_data.append({
                'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
                'Timeframe': current_timeframe,
                'Ticker': ticker,
                'Metric': 'Volume',
                'Value': f"{latest['Volume']:,.0f}",
                'Details': f"{vol_ratio:.2f}x average"
            })
        
        # Ratio Analysis
        if ratio_ticker:
            ratio_result = RatioAnalyzer.analyze_relative_strength(ticker, ratio_ticker)
            table_data.append({
                'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
                'Timeframe': '3mo',
                'Ticker': f"{ticker} vs {ratio_ticker}",
                'Metric': 'Relative Strength',
                'Value': f"{ratio_result['relative_strength']:.2f}x",
                'Details': f"Stock: {ratio_result['stock_return']:.2f}%, Benchmark: {ratio_result['benchmark_return']:.2f}%"
            })
        
        # Multi-timeframe signals
        if timeframe_signals:
            for tf, data in timeframe_signals.items():
                table_data.append({
                    'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
                    'Timeframe': tf,
                    'Ticker': ticker,
                    'Metric': 'Signal',
                    'Value': data['signal'],
                    'Details': f"Score: {data['score']:.2f}, Strategy: {data['strategy']}"
                })
        
        # Elliott Wave
        elliott = ElliottWaveAnalyzer.detect_elliott_wave(df)
        table_data.append({
            'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
            'Timeframe': current_timeframe,
            'Ticker': ticker,
            'Metric': 'Elliott Wave',
            'Value': elliott['wave'],
            'Details': f"Confidence: {elliott['confidence']}%, Bias: {elliott.get('action_bias', 'N/A')}"
        })
        
        # Final Signal
        table_data.append({
            'Timestamp': current_time.strftime('%Y-%m-%d %H:%M') if hasattr(current_time, 'strftime') else str(current_time),
            'Timeframe': 'Combined',
            'Ticker': ticker,
            'Metric': 'FINAL SIGNAL',
            'Value': f"{signal.action} ({signal.confidence:.1f}%)",
            'Details': f"Entry: â‚¹{signal.entry_price:.2f}, Target: â‚¹{signal.target_price:.2f}, SL: â‚¹{signal.stop_loss:.2f}"
        })
        
        # Create DataFrame and display
        table_df = pd.DataFrame(table_data)
        
        # Display with filters
        st.dataframe(
            table_df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "Timestamp": st.column_config.TextColumn("Timestamp", width="medium"),
                "Timeframe": st.column_config.TextColumn("Timeframe", width="small"),
                "Ticker": st.column_config.TextColumn("Ticker", width="medium"),
                "Metric": st.column_config.TextColumn("Metric", width="medium"),
                "Value": st.column_config.TextColumn("Value", width="medium"),
                "Details": st.column_config.TextColumn("Details", width="large")
            }
        )
        
        # Download button for the table
        csv = table_df.to_csv(index=False)
        st.download_button(
            label="ðŸ“¥ Download Analysis Table (CSV)",
            data=csv,
            file_name=f"analysis_table_{ticker}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
        
        report = f"""
TRADING ANALYSIS REPORT
Generated: {datetime.now(pytz.timezone('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S IST')}

Instrument: {instrument} ({ticker})
Trading Style: {trading_style}
Timeframe: {timeframe}
Period: {period}

=== SIGNAL ===
Action: {signal.action}
Confidence: {signal.confidence:.1f}%
Strategy: {signal.strategy}

=== PRICE LEVELS ===
Entry Price: â‚¹{signal.entry_price:.2f}
Target Price: â‚¹{signal.target_price:.2f}
Stop Loss: â‚¹{signal.stop_loss:.2f}
Risk:Reward: 1:{signal.risk_reward:.2f}

=== SUPPORT & RESISTANCE ===
Strong Support: â‚¹{signal.strong_support:.2f}
Strong Resistance: â‚¹{signal.strong_resistance:.2f}

=== SENTIMENT ===
Sentiment Score: {signal.sentiment_score:.3f}
Summary: {signal.sentiment_summary}

=== Z-SCORE ===
Current Z-Score: {signal.zscore:.2f}
Interpretation: {signal.zscore_interpretation}

=== BACKTEST RESULTS ===
Total Trades: {backtest_result.total_trades}
Win Rate: {backtest_result.win_rate:.1f}%
Total Return: {backtest_result.total_return:.2f}%
Profit Factor: {backtest_result.profit_factor:.2f}
Max Drawdown: {backtest_result.max_drawdown:.2f}%

=== DETAILED SUMMARY ===
{signal.detailed_summary}

=== REASONING ===
{signal.reasoning}

DISCLAIMER: This is for educational purposes only. Not financial advice.
"""
        
        st.download_button(
            label="ðŸ“¥ Download Analysis Report",
            data=report,
            file_name=f"trading_analysis_{ticker}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain"
        )
    
    else:
        # Welcome screen
        st.info("ðŸ‘ˆ Configure your settings in the sidebar and click 'Fetch & Analyze' to begin")
        
        st.markdown("""
        ### Welcome to the Professional Trading System
        
        This advanced trading application provides:
        
        âœ… **Multi-timeframe Analysis** - Analyze across different timeframes
        
        âœ… **Intelligent Strategy Selection** - Automatically selects best strategy based on market structure
        
        âœ… **Comprehensive Indicators** - RSI, MACD, Bollinger Bands, ADX, Stochastic, and more
        
        âœ… **Backtesting Validation** - Verify signals with historical performance
        
        âœ… **Risk Management** - Clear entry, target, and stop-loss levels
        
        âœ… **News Integration** - Stay updated with latest market news
        
        âœ… **Psychology Guidance** - Overcome emotional trading pitfalls
        
        #### Supported Instruments:
        - Indian Indices (NIFTY 50, Bank NIFTY, SENSEX)
        - Cryptocurrencies (Bitcoin, Ethereum)
        - Commodities (Gold, Silver)
        - Forex (USD/INR, EUR/USD)
        - Custom stocks and tickers
        
        #### Trading Styles:
        - **Scalping**: Quick in-and-out trades (minutes)
        - **Day Trading**: Intraday positions (hours)
        - **Swing Trading**: Multi-day positions (days to weeks)
        - **Positional Trading**: Long-term positions (weeks to months)
        """)

if __name__ == "__main__":
    main()

"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COMPREHENSIVE PROMPT FOR PROFESSIONAL MULTI-TIMEFRAME TRADING SYSTEM
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

APPLICATION OVERVIEW:
This is an advanced AI-powered trading system that combines technical analysis, 
Elliott Wave theory, Fibonacci levels, sentiment analysis, and machine learning 
optimization to generate high-probability trading signals with a target of 20%+ 
annual returns.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CORE FEATURES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. MULTI-INSTRUMENT SUPPORT
   - Indian Indices: NIFTY 50, Bank NIFTY, SENSEX
   - Cryptocurrencies: Bitcoin (BTC-USD), Ethereum (ETH-USD)
   - Commodities: Gold (GC=F), Silver (SI=F)
   - Forex: USD/INR, EUR/USD
   - Custom tickers via yfinance

2. TRADING STYLES
   - Scalping: 1m, 5m, 15m timeframes - Quick in/out
   - Day Trading: 5m, 15m, 1h - Intraday positions
   - Swing Trading: 1h, 4h, 1d - Multi-day holds
   - Positional: 1d timeframe - Long-term positions

3. ADVANCED TECHNICAL ANALYSIS
   - 15+ Indicators: RSI, MACD, Bollinger Bands, ADX, Stochastic, ATR
   - Moving Averages: SMA 20/50/200, EMA 12/26
   - Support/Resistance: Multiple strong levels with touch count
   - Elliott Wave: 5-wave impulse and 3-wave correction detection
   - Fibonacci: Retracement (38.2%, 50%, 61.8%) and extensions
   - RSI Divergence: Bullish/bearish early warning signals
   - Volume Analysis: Confirmation and conviction measurement
   - Volatility: Historical vol, ATR, regime identification

4. PATTERN RELIABILITY ANALYSIS (CRITICAL INNOVATION)
   - Tests ALL patterns on recent history for accuracy
   - Identifies WHICH pattern the market follows most reliably
   - Weights signals by pattern reliability (70%+ = primary driver)
   - Adapts dynamically - what works TODAY gets highest weight
   - Rankings: Elliott Wave, Fibonacci, S/R, MA, RSI, MACD

5. NEWS SENTIMENT ANALYSIS
   - VADER sentiment on top 5 headlines
   - Score from -1 (very negative) to +1 (very positive)
   - Adjusts trading signals based on news catalyst
   - Handles both n['title'] and n['content']['title'] formats

6. RATIO ANALYSIS
   - Compares stock vs benchmark (NIFTY 50 default)
   - Calculates 3-month relative strength
   - Identifies outperformers vs underperformers
   - Adjusts signals (strong outperform = bullish bias)
   - Optional: Compare any two custom tickers

7. STRATEGY OPTIMIZATION FOR 20% ANNUAL RETURNS
   - Parameter grid search: entry thresholds, stop-loss, take-profit
   - Tests combinations to maximize annual return
   - Minimum 1.5:1 risk/reward enforced
   - Only trades setups that historically achieved target returns
   - Falls back to HOLD if optimization fails

8. COMPREHENSIVE BACKTESTING
   - Elliott Wave confirmation in entry logic
   - Optimized parameters (entry threshold, SL, TP)
   - Calculates: Win rate, profit factor, max drawdown
   - Annual return, Sharpe ratio
   - CRITICAL: Overrides signal to HOLD if backtest < 80% of target

9. MULTI-TIMEFRAME CONFLUENCE
   - Analyzes 3 timeframes simultaneously
   - Shows what EACH timeframe signals and why
   - Requires alignment for high-confidence trades
   - Explains final decision logic

10. VOLATILITY-ADJUSTED RISK MANAGEMENT
    - Historical volatility (annualized)
    - ATR-based volatility
    - Volatility percentile vs history
    - Regime: EXTREME HIGH, HIGH, NORMAL, LOW, EXTREME LOW
    - Impact on position sizing and stop distances

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SIGNAL GENERATION LOGIC:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

STEP 1: Calculate all indicators
STEP 2: Run strategy (trend following, mean reversion, momentum, breakout, scalping)
STEP 3: Test pattern reliability - which patterns work best?
STEP 4: Weight signals by reliability scores
STEP 5: Add sentiment adjustment (+/- 1.5)
STEP 6: Add volume confirmation (if available)
STEP 7: Add Elliott Wave bias
STEP 8: Add RSI divergence
STEP 9: Add Fibonacci level proximity
STEP 10: Add S/R level proximity
STEP 11: Add ratio analysis (relative strength)
STEP 12: CRITICAL - Boost score if most reliable pattern confirms
STEP 13: Determine BUY/SELL/HOLD based on adjusted score
STEP 14: Override if most reliable pattern strongly contradicts
STEP 15: Calculate entry/target/SL using most reliable pattern levels
STEP 16: Run backtest with optimized parameters
STEP 17: Override to HOLD if backtest < target returns

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
WHY THIS APPROACH WORKS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. PATTERN RELIABILITY = STATISTICAL EDGE
   - Markets aren't random - they follow patterns
   - Different patterns work in different market conditions
   - By testing which pattern is most accurate NOW, we adapt
   - 75% reliable pattern = 3:1 odds in your favor

2. MULTI-FACTOR CONFLUENCE = MULTIPLICATIVE PROBABILITY
   - Single indicator: ~60% win rate
   - 2 indicators aligned: ~70% win rate
   - 3+ indicators + high reliability pattern: ~80%+ win rate
   - Probability multiplies, not adds

3. OPTIMIZATION = SYSTEMATIC EDGE
   - Tests 48 parameter combinations
   - Finds optimal entry/exit for THIS instrument
   - Enforces minimum risk/reward
   - Only trades setups that historically worked

4. BACKTEST VALIDATION = REALITY CHECK
   - Prevents curve-fitting and false signals
   - Overrides signal if historically unprofitable
   - Protects capital from losing strategies
   - Requires 80% of target return as minimum

5. VOLATILITY ADJUSTMENT = ADAPTIVE RISK
   - High vol = wider stops, smaller positions
   - Low vol = tighter stops, larger positions
   - Matches risk to market conditions

6. PSYCHOLOGY INTEGRATION
   - Reminds traders about FOMO, greed, fear
   - Emphasizes patience and discipline
   - Confluence gives confidence to hold winners
   - Logic-based decisions vs emotional reactions

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
USER INTERFACE COMPONENTS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SIDEBAR:
- Instrument selector
- Trading style (Scalping/Day/Swing/Positional)
- Timeframe and period
- Ratio analysis toggle
- Custom ticker comparison
- Target annual return slider (10-50%)
- API delay control
- Fetch & Analyze button

MAIN DISPLAY:
1. Optimization status banner
2. Signal box (BUY/SELL/HOLD with confidence)
3. Key metrics row: Price, Target, SL, R:R, RSI, Volatility
4. Volatility analysis section
5. Multiple S/R levels (top 5 supports and resistances)
6. Detailed 200-word market summary
7. Pattern reliability rankings with gauge chart
8. Multi-timeframe confluence explanation
9. Support/Resistance with strength and dates
10. Z-Score mean reversion analysis
11. News sentiment with headline breakdown
12. Ratio analysis (if enabled)
13. Volume analysis (if available)
14. Technical reasoning
15. Advanced chart with Elliott Wave annotations and Fibonacci levels
16. Optimized backtest results with annual return
17. Backtest interpretation (validated or not)
18. Market conditions summary
19. Trading psychology guide
20. COMPREHENSIVE DATA TABLE (all metrics, timeframes, prices, indicators)
21. Download buttons (report + CSV table)

COMPREHENSIVE DATA TABLE INCLUDES:
- Timestamp for each metric
- Timeframe context
- Ticker symbol
- Metric name (RSI, MACD, Fibonacci levels, S/R, etc.)
- Current value
- Detailed explanation
- Shows Fibonacci 50% level = â‚¹X at timeframe Y
- All support/resistance with prices and distances
- Volatility metrics
- Volume ratios
- Multi-timeframe signals
- Elliott Wave position
- Final signal with entry/target/SL

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
API RATE LIMITING:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

- 1.5 second delay between yfinance requests (configurable)
- Caching for 5 minutes to avoid repeated calls
- Button-based fetch (not auto-refresh)
- UI persists after button click
- Handles timezone conversion to IST

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RISK MANAGEMENT:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Position Sizing: Adjusted by volatility regime
2. Stop Loss: 2-2.5x ATR (optimized)
3. Take Profit: 3-4x ATR (optimized)
4. Minimum R:R: 1.5:1 enforced
5. Backtest Override: HOLD if annual return < target
6. Pattern Override: HOLD if most reliable pattern contradicts
7. Psychology Reminders: Combat FOMO, greed, fear

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXAMPLE SCENARIO:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

USER SELECTS: NIFTY 50, Swing Trading, 1h timeframe, 6mo period, 20% target

SYSTEM DOES:
1. Fetches 6 months of 1h data
2. Calculates 15+ indicators
3. Tests pattern reliability:
   - Elliott Wave: 76% accurate â†’ PRIMARY
   - Fibonacci: 68% â†’ Secondary
   - S/R: 62% â†’ Tertiary
4. Generates signals from all strategies
5. Weights by reliability (Elliott = 3x, Fib = 2x)
6. Elliott shows "Wave 3 Bullish" â†’ +2 points
7. RSI bullish divergence â†’ +1 point
8. Near Fibonacci 61.8% support â†’ +1 point
9. High volume on up move â†’ +1.5 points
10. Total score: 7.5 â†’ STRONG BUY
11. Optimizes parameters: finds 3.0 entry, 2.0 SL, 3.5 TP works best
12. Backtests: 24% annual return, 68% win rate â†’ VALIDATED
13. Generates signal: BUY at â‚¹21,500, Target â‚¹22,100, SL â‚¹21,200
14. Displays comprehensive table showing all calculations

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DEPENDENCIES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

streamlit
yfinance
pandas
numpy
plotly
nltk (with vader_lexicon)
pytz

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HOW TO RUN:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

streamlit run trading_system.py

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DISCLAIMER:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

This tool is for EDUCATIONAL PURPOSES ONLY. Past performance does not guarantee
future results. Trading involves substantial risk of loss. Always do your own
research and consult with licensed financial advisors before making investment
decisions.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
